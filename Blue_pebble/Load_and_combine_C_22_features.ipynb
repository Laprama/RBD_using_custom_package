{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5740496-8527-4ef8-b496-8b8bbd84cd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/home/ko20929/.conda/envs/sktime_latest/lib/python3.11/site-packages/antropy/fractal.py:197: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @jit((types.Array(types.float64, 1, \"C\", readonly=True), types.int32))\n"
     ]
    }
   ],
   "source": [
    "from IPython.utils import io\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "import joblib\n",
    "from os.path import exists\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import mne\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#From my EEG package \n",
    "import run_expts\n",
    "import format_eeg_data\n",
    "import constants\n",
    "import eeg_stat_ts\n",
    "import custom_ts_length\n",
    "\n",
    "from sktime.transformations.panel.catch22 import Catch22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17edeb29-d7e7-4882-8986-393fdfe6992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     #Generate the rename mapping dictionary to rename the transformed dataframe using more appropriate names____________________\n",
    "channel_names = eeg_data_df.columns\n",
    "new_names = [channel + '_' + feature for channel in channel_names for feature in feature_list] #This is hard to follow but it is correct\n",
    "\n",
    "rename_mapping_dict = {}\n",
    "for old_name, new_name in zip(transformed_names,new_names):\n",
    "    rename_mapping_dict[old_name] = new_name\n",
    "    \n",
    "final_transformed_df = transformed_df.rename(rename_mapping_dict, axis=1)\n",
    "\n",
    "\n",
    "#5. Save everything in the appropriate place ---->  final_transformed_df, groups , y\n",
    "folder = 'Catch_22_features/'\n",
    "final_transformed_df.to_hdf(folder + data_type + '_c_22_feautures.h5' , key = 'df', mode = 'w')\n",
    "groups.to_hdf(folder + data_type + '_groups.h5' , key = 'df', mode = 'w')\n",
    "y.to_hdf(folder + data_type + '_y.h5' , key = 'df', mode = 'w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60f63291-f77e-4de5-a225-115e6d0768a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = ['Wake','N1', 'N2', 'N3', 'REM']\n",
    "\n",
    "#These were the arrays in the bash script \n",
    "data_type_samples = {'Wake' : (0,55) , 'N1' : (0,70) , 'N2' : (0,70) , 'N3': (0,71) , 'REM' : (0,68) } \n",
    "\n",
    "feature_list = ['DN_HistogramMode_5', 'DN_HistogramMode_10', 'SB_BinaryStats_diff_longstretch0', 'DN_OutlierInclude_p_001_mdrmd', 'DN_OutlierInclude_n_001_mdrmd', \n",
    " 'CO_f1ecac', 'CO_FirstMin_ac', 'SP_Summaries_welch_rect_area_5_1', 'SP_Summaries_welch_rect_centroid', 'FC_LocalSimple_mean3_stderr', 'CO_trev_1_num', \n",
    " 'CO_HistogramAMI_even_2_5', 'IN_AutoMutualInfoStats_40_gaussian_fmmi', 'MD_hrv_classic_pnn40', 'SB_BinaryStats_mean_longstretch1', 'SB_MotifThree_quantile_hh',\n",
    " 'FC_LocalSimple_mean1_tauresrat', 'CO_Embed2_Dist_tau_d_expfit_meandiff', 'SC_FluctAnal_2_dfa_50_1_2_logi_prop_r1', 'SC_FluctAnal_2_rsrangefit_50_1_logi_prop_r1', \n",
    " 'SB_TransitionMatrix_3ac_sumdiagcov', 'PD_PeriodicityWang_th0_01' , 'StandardDeviation' , 'Mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f8e0247-957b-45ff-b6be-2dd41cd704c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating for Wake ....\n",
      "Generating for N1 ....\n",
      "Generating for N2 ....\n",
      "Generating for N3 ....\n",
      "Generating for REM ....\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.439596176147461"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "final_feature_dfs = {}\n",
    "for data_type in data_types:\n",
    "    print('Generating for ' + data_type + ' ....')\n",
    "    data_type_dfs = []\n",
    "    for path_num in range(data_type_samples[data_type][0] , data_type_samples[data_type][1]+1):\n",
    "        transformed_df = pd.read_hdf('/user/home/ko20929/work/RBD_using_custom_package/Blue_pebble/C_22_data/' + str(path_num) + data_type + '_c_22_features.h5')\n",
    "        data_type_dfs.append(transformed_df)\n",
    "        \n",
    "    full_df = pd.concat(data_type_dfs, axis = 0)\n",
    "    transformed_names = full_df.columns\n",
    "    channel_names = constants.channel_list\n",
    "    new_names = [channel + '_' + feature for channel in channel_names for feature in feature_list] #This is hard to follow but it is correct\n",
    "    \n",
    "    rename_mapping_dict = {}\n",
    "    for old_name, new_name in zip(transformed_names,new_names):\n",
    "        rename_mapping_dict[old_name] = new_name\n",
    "        \n",
    "    final_transformed_df = full_df.rename(rename_mapping_dict, axis=1)\n",
    "    \n",
    "    final_transformed_df.to_hdf('/user/home/ko20929/work/RBD_using_custom_package/Blue_pebble/C_22_data/Full_dfs/' + data_type + '_full_c_22_features.h5', key = 'df', mode = 'w')\n",
    "    final_feature_dfs[data_type] = final_transformed_df\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "t2-t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "862221a8-71ce-49b8-8eed-50f6f3713fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "['selected_paths', 's_class_list', 's_night_list', 's_sleep_type', 's_p_id']\n",
    "\n",
    "for data_type in ['Wake','N1', 'N2', 'N3', 'REM']:\n",
    "    paths = joblib.load(data_type+ '_paths.pkl')\n",
    "    y = pd.Series(paths['s_class_list']).map({'HC': 0 , 'PD' : 1 , 'PD+RBD' : 2 , 'RBD' : 3})\n",
    "    groups = pd.Series( paths['s_p_id'] )\n",
    "    \n",
    "    groups.to_hdf('C_22_data/Full_dfs/' + data_type + '_groups.h5', key = 'df' , mode = 'w')\n",
    "    y.to_hdf('C_22_data/Full_dfs/' + data_type + '_y.h5', key = 'df' , mode = 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8b92e240-5342-4195-9eec-69bd1a7cbf49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pd.read_hdf('test_y.h5') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ab54d59-38ea-41a7-9c41-c70fa390f88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N1_paths = joblib.load('N1_paths.pkl')\n",
    "len(N1_paths['selected_paths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f686ae8a-aaac-4cae-bd9e-a15ba424db0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['selected_paths', 's_class_list', 's_night_list', 's_sleep_type', 's_p_id'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N1_paths.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
