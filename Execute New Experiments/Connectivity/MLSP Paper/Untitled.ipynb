{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01313b9f-a351-46a7-9647-7f440b01323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "methods = ['coh', 'imcoh', 'plv', 'ciplv', 'ppc', 'pli', 'dpli', 'wpli', 'wpli2_debiased'] #removed cohy because it's not there in results folder\n",
    "\n",
    "data_types = ['REM', 'N1', 'N2', 'N3', 'Wake']\n",
    "expt_num = 1\n",
    "save_folder = '/user/home/ko20929/work/RBD_using_custom_package/Execute New Experiments/Connectivity/Connectivity_Results/Experiment_set_2/'\n",
    "\n",
    "#Try loading a results file\n",
    "method = methods[0]\n",
    "data_type = data_types[1]\n",
    "\n",
    "# Create summary results dictionary that will be filled and populated\n",
    "summary_results_dict = {}\n",
    "summary_results_dict['metric'] = []\n",
    "for data_type in data_types:\n",
    "    summary_results_dict[data_type + '_model'] = []\n",
    "    summary_results_dict[data_type + '_acc'] = []\n",
    "    summary_results_dict[data_type + '_acc' + '_std'] = []\n",
    "\n",
    "#Dictionary to store raw results for calculation of distribution(s) and statistical tests \n",
    "raw_results = {}\n",
    "for method in methods:\n",
    "    raw_results[method] = {}\n",
    "\n",
    "\n",
    "#error dict can catch those metrics / data types for which we don't have results files\n",
    "error_dict = {}\n",
    "for method in methods:\n",
    "    error_dict[method] = []\n",
    "    \n",
    "    summary_results_dict['metric'].append(method)\n",
    "    \n",
    "    for data_type in data_types:\n",
    "        try:\n",
    "            load_path = save_folder + data_type + method + '_expt_' + str(expt_num) + '_' + 'raw_clfs_results.h5'\n",
    "            \n",
    "            results_df = pd.read_hdf(load_path)\n",
    "            results_df = results_df[ ['random_state', 'y_true'] + [col for col in results_df.columns if 'Ada' in col] ]\n",
    "            \n",
    "            raw_results[method][data_type] = results_df\n",
    "\n",
    "        \n",
    "            \n",
    "            res_df = run_expts.generate_subset_acc_std(results_df, return_df = True)\n",
    "            # This will get you best performing Ada Model and Value for each method for each data type\n",
    "            best_acc = res_df.mean(axis = 0)[1:].max()\n",
    "            best_model = res_df.mean(axis = 0)[1:].idxmax()\n",
    "\n",
    "            #Use the summary res_df to identify best model, keep raw results of best model to calculate the true std\n",
    "            results_df_trimmed = results_df[ list(results_df.columns)[:2] + [col for col in results_df.columns if best_model[:-4] in col] ]\n",
    "            per_fold_metrics = calculate_results.calc_per_fold_metrics(results_df)\n",
    "            overalled_weighted_df = calculate_results.overall_weighted_metrics(per_fold_metrics)\n",
    "            \n",
    "            std_val = overalled_weighted_df[best_model + '_std'].values[0]\n",
    "\n",
    "            summary_results_dict[data_type + '_model'].append(best_model[:-10])\n",
    "            summary_results_dict[data_type + '_acc'].append(best_acc)\n",
    "            summary_results_dict[data_type + '_acc' + '_std'].append(std_val)\n",
    "            \n",
    "        except:\n",
    "            error_dict[method].append(data_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
