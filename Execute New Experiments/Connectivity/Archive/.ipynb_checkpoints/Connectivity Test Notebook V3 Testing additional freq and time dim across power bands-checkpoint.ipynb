{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4f2e69a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/home/ko20929/.conda/envs/sktime_latest/lib/python3.11/site-packages/antropy/fractal.py:197: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit((types.Array(types.float64, 1, \"C\", readonly=True), types.int32))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mne as mne\n",
    "import os \n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import constants\n",
    "from IPython.utils import io\n",
    "import time\n",
    "import sys\n",
    "import yasa\n",
    "from scipy.signal import welch\n",
    "\n",
    "#Import my modules\n",
    "import format_eeg_data\n",
    "import constants\n",
    "import eeg_stat_ts\n",
    "\n",
    "from mne_connectivity import spectral_connectivity_epochs\n",
    "from mne.datasets import sample\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.signal import welch\n",
    "import yasa\n",
    "import constants\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3937a12c-9e4b-4ee8-b1e8-64abe8ddd248",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = ['Wake', 'N1', 'N2','N3', 'REM'][int(sys.argv[1])]\n",
    "folder = '/user/home/ko20929/work/RBD_using_custom_package/Blue_pebble/'\n",
    "paths = joblib.load(folder + data_type + '_paths.pkl')\n",
    "method = 'pli'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b764c4f-57b2-48e1-a82a-e030feb7c3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "connectivity_df_list = []\n",
    "\n",
    "t1 = time.time()\n",
    "#Because I want std of distribution each power band needs to be processed seperately\n",
    "power_bands_dict = {'delta' : (0.5,4) , 'theta' : (4,8) , 'alpha' : (8,12) , 'sigma' : (12,16) , 'beta' : (16,30) , 'gamma' : (30,40), 'all' : (0.5,40) }\n",
    "\n",
    "    \n",
    "for path in paths['selected_paths']:\n",
    "    #For each path the power band features (mean and std) are calculated seperately then concatenated\n",
    "    power_band_dfs = []\n",
    "    for power_band in power_bands_dict.keys():\n",
    "        fmin = power_bands_dict[power_band][0]\n",
    "        fmax = power_bands_dict[power_band][1]\n",
    "        \n",
    "        \n",
    "        channels = constants.channel_list\n",
    "        channel_names = constants.channel_list\n",
    "        \n",
    "        data_epo = mne.read_epochs(path)\n",
    "        df_full = data_epo.to_data_frame()\n",
    "        \n",
    "        \n",
    "        #generate coherence data across electrodes\n",
    "        con_pli =  spectral_connectivity_epochs(data_epo , method=method , sfreq=256,fmin=fmin, fmax=fmax, faverage=False)\n",
    "        \n",
    "        connectivity_data = con_pli.get_data('dense')\n",
    "        channel_data = connectivity_data\n",
    "        \n",
    "        # Create an empty DataFrame for the means\n",
    "        df = pd.DataFrame(index=channel_names, columns=channel_names)\n",
    "        \n",
    "        # Fill the DataFrame with connectivity values\n",
    "        for i in range(len(channel_names)):\n",
    "            for j in range(len(channel_names)):\n",
    "                channel_1 = channel_names[i]\n",
    "                channel_2 = channel_names[j]\n",
    "                connectivity_value = channel_data[i, j]\n",
    "                df.loc[channel_1, channel_2] = connectivity_value.mean()\n",
    "                df.loc[channel_2, channel_1] = connectivity_value.mean()\n",
    "                \n",
    "        df_mean = df.apply(pd.to_numeric)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Create an empty DataFrame for the stds\n",
    "        df = pd.DataFrame(index=channel_names, columns=channel_names)\n",
    "        \n",
    "        # Fill the DataFrame with connectivity values\n",
    "        for i in range(len(channel_names)):\n",
    "            for j in range(len(channel_names)):\n",
    "                channel_1 = channel_names[i]\n",
    "                channel_2 = channel_names[j]\n",
    "                connectivity_value = channel_data[i, j]\n",
    "                df.loc[channel_1, channel_2] = connectivity_value.std()\n",
    "                df.loc[channel_2, channel_1] = connectivity_value.std()\n",
    "                \n",
    "        df_std = df.apply(pd.to_numeric)\n",
    "        \n",
    "        new_df_row = {}\n",
    "        \n",
    "        for df , df_type in zip([df_mean , df_std] , ['mean' , 'std' ] ): \n",
    "\n",
    "            #4. Go through channel vs channel matrix dfs and transform into features for single row in df\n",
    "            for i, channel in enumerate(channels):\n",
    "                for channel_2 in channels[i+1:]:\n",
    "                    val = df.loc[channel, channel_2]\n",
    "                    new_df_row[power_band + '_' + df_type + '_' + channel + '_' + channel_2] = [val]\n",
    "                    \n",
    "        new_df = pd.DataFrame.from_dict(new_df_row, orient = 'columns')\n",
    "        \n",
    "        power_band_dfs.append(new_df)\n",
    "    \n",
    "    sample_df = pd.concat(power_band_dfs, axis = 1)\n",
    "    connectivity_df_list.append(sample_df)\n",
    "\n",
    "save_folder = '/user/home/ko20929/work/RBD_using_custom_package/Blue_pebble/Connectivity/test/'\n",
    "connectivity_df = pd.concat(connectivity_df_list)\n",
    "\n",
    "connectivity_df.to_hdf(save_folder + data_type + '_' + method + '_mean_and_std_' + '_df.h5' , key = 'df' , mode = 'w')\n",
    "\n",
    "t2 = time.time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
