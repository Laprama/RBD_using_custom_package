{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bef20a1-752e-4c69-983a-ace8652ac143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/home/ko20929/.conda/envs/sktime_latest/lib/python3.11/site-packages/antropy/fractal.py:197: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit((types.Array(types.float64, 1, \"C\", readonly=True), types.int32))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mne as mne\n",
    "import os \n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import constants\n",
    "from IPython.utils import io\n",
    "import time\n",
    "import sys\n",
    "import yasa\n",
    "from scipy.signal import welch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Import my modules\n",
    "import format_eeg_data\n",
    "import constants\n",
    "import eeg_stat_ts\n",
    "import run_expts\n",
    "\n",
    "#TS Fresh Parameter Settings\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters\n",
    "from tsfresh.feature_extraction import MinimalFCParameters\n",
    "from tsfresh.feature_extraction import EfficientFCParameters\n",
    "from tsfresh.feature_extraction import extract_features\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Set display options to show all rows and columns\n",
    "pd.set_option('display.max_rows', 3000)  # Show rows\n",
    "pd.set_option('display.max_columns', 160)  # Show columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6048ac34-07a3-472d-9508-0d7d0d4c5bc2",
   "metadata": {},
   "source": [
    "I think I should test the random forest random seed. As silly as that sounds? Incase by chance that is impacting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "806054df-ff71-41fe-950b-05a4ed2671d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit the grids based on best hyperparameters per Hyperparameter Tuning Analysis 5 worksheet \n",
    "RF_param_grid = { \n",
    "    'n_estimators': [1,2,3, 10],\n",
    "    'max_features': [None, 'sqrt'],\n",
    "    'max_depth' : [2,3,5],\n",
    "    'criterion' :['gini',  'entropy'],\n",
    "    'min_samples_split' : [3,4,5]}\n",
    "\n",
    "DT_params =  {\n",
    "    'min_samples_leaf': [1, 2, 3 , 5 ,10],\n",
    "    'max_depth': [1, 2, 3, 5, None],\n",
    "    'criterion': [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "Ada_grid =  { \n",
    "    'n_estimators': [2, 3, 5, 10, 20, 40, 50, 100],\n",
    "    'learning_rate': [0.01,0.05,  0.1, 0.2, 0.4, 10.0],\n",
    "    }\n",
    "\n",
    "SVC_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "                'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "                'kernel': ['linear', 'rbf']} \n",
    "\n",
    "RF_param_grid = { \n",
    "    'n_estimators': [1,10],\n",
    "    'max_features': ['sqrt'],\n",
    "    'max_depth' : [5],\n",
    "    'criterion' :['gini'],\n",
    "    'min_samples_split' : [4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ced1348f-6a83-43b6-b527-60e4e436fc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_Fresh_setting, connectivity_setting = 'Minimal' , 'beta'\n",
    "RF_dict = {'RF' : GridSearchCV( RandomForestClassifier(), RF_param_grid , refit = True, verbose = 1, cv = GroupKFold(n_splits = 5)  ) }\n",
    "data_type, expt_num , num_splits , clf_dict = 'N1', 1, 5,RF_dict "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b901d0-e537-4200-83e7-6e66c369e6a6",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a04040a2-02a6-4e61-96ef-c47f712e0b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23-Oct-23 18:35:16 | WARNING | Dependency not available for matrix_profile, this feature will be disabled!\n",
      "Feature Extraction: 100%|██████████| 120/120 [00:03<00:00, 32.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1950\n",
      "1950\n",
      "1948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.843061685562134"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the features \n",
    "t1 = time.time()\n",
    "\n",
    "load_path = '/user/home/ko20929/work/RBD_using_custom_package/Data/freq_6_second_files/'\n",
    "load_path_bpw = '/user/home/ko20929/work/RBD_using_custom_package/Data/freq_6_second_files/'\n",
    "load_path_max_freqs = '/user/home/ko20929/work/RBD_using_custom_package/Execute New Experiments/Baseline_Extensions/Gen_New_Features/generated_feats/'\n",
    "\n",
    "loaded_data = {}\n",
    "\n",
    "X_y_groups = {}\n",
    "    \n",
    "X_bpw = pd.read_hdf(load_path_bpw + data_type +  'six_second_freq_df.h5', key='df', mode='r')\n",
    "y = pd.read_hdf(load_path + data_type +  '_y.h5', key='df', mode='r') \n",
    "groups = pd.read_hdf(load_path + data_type +  '_groups.h5', key='df', mode='r')\n",
    "X_bpw, y , groups = X_bpw.reset_index(drop = True) , y.reset_index(drop = True) , groups.reset_index(drop = True)\n",
    "\n",
    "X_max_freqs = pd.read_hdf(load_path_max_freqs + data_type +  'six_second_max_freq_stats_df.h5', key='df', mode='r')\n",
    "X_max_freqs = X_max_freqs.reset_index(drop = True)\n",
    "\n",
    "X = pd.concat([X_bpw , X_max_freqs], axis = 1)\n",
    "\n",
    "#Transform the X into TS_Fresh Features___\n",
    "# 1. Convert to TS_Fresh format Dataframe \n",
    "ts_fresh_df = format_eeg_data.convert_sktime_df_to_ts_fresh_format(X, ts_cols = list(X.columns))\n",
    "\n",
    "# 2. Extract TS_Fresh Features from the dataframe\n",
    "if TS_Fresh_setting == 'Minimal':\n",
    "    settings = MinimalFCParameters()\n",
    "\n",
    "extracted_ts_fresh_df = extract_features(ts_fresh_df, column_id = 'id' , column_sort = 'time', default_fc_parameters=settings)\n",
    "\n",
    "# 3. Asign extract_ts_fresh_df to the variable X\n",
    "X = extracted_ts_fresh_df.copy()\n",
    "print(len(X.columns))\n",
    "#Drop columns where all values are NA \n",
    "X = X.dropna(axis = 1)\n",
    "print(len(X.columns))\n",
    "\n",
    "#Drop columns where all values are the same\n",
    "# Find columns where all values are the same\n",
    "same_value_columns = X.columns[X.nunique() == 1]\n",
    "# Drop columns with the same values\n",
    "X = X.drop(columns=same_value_columns)\n",
    "print(len(X.columns))\n",
    "\n",
    "#___________load the appropriate connectivity features don't concatenate to non connectivity features until after dictionary generation\n",
    "\n",
    "connectivity_folder = '/user/home/ko20929/work/RBD_using_custom_package/Blue_pebble/Connectivity/'\n",
    "X_connectivity = pd.read_hdf(connectivity_folder + data_type+ '_pli__df.h5')\n",
    "\n",
    "X_connectivity = X_connectivity[[col for col in X_connectivity.columns if connectivity_setting in col]]\n",
    "\n",
    "#Generate a region to features dictionary - this will enable us to run expts regionally as before\n",
    "regional_features_dict = {}\n",
    "region_channel_dict = constants.region_to_channel_dict\n",
    "regions = list(region_channel_dict.keys())\n",
    "for region in regions:\n",
    "    region_features = [col for col in X.columns if region + '_' in col]\n",
    "    if len(region_features) > 0 : \n",
    "        regional_features_dict[region] = region_features + list(X_connectivity.columns)\n",
    "\n",
    "#Now concatenate the regional frequency features dataframe with the connectivity dataframe\n",
    "X = X.reset_index(drop=True)\n",
    "X_connectivity = X_connectivity.reset_index(drop=True)\n",
    "X = pd.concat([X , X_connectivity], axis = 1)\n",
    "\n",
    "t2 = time.time()\n",
    "t2-t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a95eb6b8-a3fe-4d24-81e8-14fb32381797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose one region , 0 = Prefrontal\n",
    "num = 0\n",
    "key = list(regional_features_dict.keys())[0]\n",
    "subset_dict =  {key : regional_features_dict[key] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b8eb214-2fc3-4ae9-a79e-1e14af9fc7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the experiment with hyperparameter tuning\n",
    "X_expt , y_expt , groups_expt, expt_info = run_expts.generate_expt_x_y_groups(X,y,groups, expt_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ca411fb-dde1-466e-a56c-a0b679e7573a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.32401704788208"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "results_df = run_expts.run_mv_tsc(X_expt,y_expt,groups_expt,clf_dict, return_df = True , subset_names_and_cols = subset_dict, random_states = [1,2], groups_for_fit = True, best_params = True)\n",
    "t2 = time.time()\n",
    "t2-t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56a9b0c1-1d92-4b3d-b8e7-72d39bf82805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>random_state</th>\n",
       "      <th>y_true</th>\n",
       "      <th>Prefrontal_RF_y_preds</th>\n",
       "      <th>y_train</th>\n",
       "      <th>Prefrontal_RF_best_clf_params</th>\n",
       "      <th>Prefrontal_RF_cv_results</th>\n",
       "      <th>Prefrontal_RF_y_train_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>[[0, 0, 1, 0, 0, 0, 1, 1], [0, 0, 0, 1, 1, 0, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[{'criterion': 'gini', 'max_depth': 5, 'max_fe...</td>\n",
       "      <td>mean_fit_time  std_fit_time  mean_score_tim...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>[[0, 0, 1, 0, 0, 1, 1, 1], [0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[{'criterion': 'gini', 'max_depth': 5, 'max_fe...</td>\n",
       "      <td>mean_fit_time  std_fit_time  mean_score_tim...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   random_state                                             y_true  \\\n",
       "0             1  [[0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 0, 1, 1, 1, ...   \n",
       "1             2  [[0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 1, 1, ...   \n",
       "\n",
       "                               Prefrontal_RF_y_preds  \\\n",
       "0  [[0, 0, 1, 0, 0, 0, 1, 1], [0, 0, 0, 1, 1, 0, ...   \n",
       "1  [[0, 0, 1, 0, 0, 1, 1, 1], [0, 0, 0, 0, 1, 0, ...   \n",
       "\n",
       "                                             y_train  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                       Prefrontal_RF_best_clf_params  \\\n",
       "0  [{'criterion': 'gini', 'max_depth': 5, 'max_fe...   \n",
       "1  [{'criterion': 'gini', 'max_depth': 5, 'max_fe...   \n",
       "\n",
       "                            Prefrontal_RF_cv_results  \\\n",
       "0     mean_fit_time  std_fit_time  mean_score_tim...   \n",
       "1     mean_fit_time  std_fit_time  mean_score_tim...   \n",
       "\n",
       "                         Prefrontal_RF_y_train_preds  \n",
       "0  [[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,...  \n",
       "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5add9f8f-c8b7-4cd9-929e-12abc46c1788",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = run_expts.generate_subset_acc_std(results_df.iloc[:,:3], return_df = True)\n",
    "acc_df = res_df[[col for col in res_df.columns if 'acc' in col]]\n",
    "mean_acc_df = pd.DataFrame( acc_df.mean(axis=0) ).T\n",
    "mean_acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637ab819-7954-4648-bf29-5b8c96ac392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.7 seconds vs. 12.94 seconds????"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
