{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58f6f3e2-f0ca-4017-a4e3-872e58def236",
   "metadata": {},
   "source": [
    "#### Create Script for running experiments for the papier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29694743-c023-42ef-bc9a-8b69a5dec541",
   "metadata": {},
   "source": [
    "Run the regional statistical features model(s) <br>\n",
    "I want to do this tuned for Ada Boost and Decision Tree <br>\n",
    "For minimal TS Fresh Features and Efficient TS Fresh Features <br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12266228-85e7-48dc-8e2d-890201679af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To make it a static features experiment, all I need to do is the below\n",
    "#WITHOUT calculating the TS Fresh features, apply the below directly to the time series\n",
    "# Defining a function to replace time series of values with their mean\n",
    "def function(x):\n",
    "    return x.values.mean()\n",
    "    \n",
    "#Construct the static features\n",
    "static_features_df = X.apply(np.vectorize(function))\n",
    "X = static_features_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a736be90-2f57-47b6-966c-a0f810ff6578",
   "metadata": {},
   "source": [
    "I need to edit the below appropriately for hyperparameter tuning and then run ittt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "731cbf99-d27f-4a45-9f3a-2f37c75d947f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/home/ko20929/.conda/envs/sktime_latest/lib/python3.11/site-packages/antropy/fractal.py:197: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit((types.Array(types.float64, 1, \"C\", readonly=True), types.int32))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mne as mne\n",
    "import os \n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import constants\n",
    "from IPython.utils import io\n",
    "import time\n",
    "import sys\n",
    "import yasa\n",
    "from scipy.signal import welch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Import my modules\n",
    "import format_eeg_data\n",
    "import constants\n",
    "import eeg_stat_ts\n",
    "import run_expts\n",
    "\n",
    "#TS Fresh Parameter Settings\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters\n",
    "from tsfresh.feature_extraction import MinimalFCParameters\n",
    "from tsfresh.feature_extraction import EfficientFCParameters\n",
    "from tsfresh.feature_extraction import extract_features\n",
    "\n",
    "# Set display options to show all rows and columns\n",
    "pd.set_option('display.max_rows', 50)  # Show rows\n",
    "pd.set_option('display.max_columns', 160)  # Show columns\n",
    "\n",
    "data_type = ['Wake','N1', 'N2', 'N3', 'REM'][0]\n",
    "TS_Fresh_setting = ['Minimal' , 'Efficient'][0]\n",
    "expt_num = [1,2,3,4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7ffe56a-26fa-4053-bcd9-ca0281f518d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the below code I can load the clfs and loop through data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c4e72b4-4457-4545-a3cc-fc5aca6c7782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change load path to the band power time series folder\n",
    "load_path = '/user/home/ko20929/work/RBD_using_custom_package/Data/freq_6_second_files/'\n",
    "load_path_bpw = '/user/home/ko20929/work/RBD_using_custom_package/Data/freq_6_second_files/'\n",
    "load_path_max_freqs = '/user/home/ko20929/work/RBD_using_custom_package/Execute New Experiments/Baseline_Extensions/Gen_New_Features/generated_feats/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95365ab9-94fa-4100-8678-5d4833fbd04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bpw = pd.read_hdf(load_path_bpw + data_type +  'six_second_freq_df.h5', key='df', mode='r')\n",
    "y = pd.read_hdf(load_path + data_type +  '_y.h5', key='df', mode='r') \n",
    "groups = pd.read_hdf(load_path + data_type +  '_groups.h5', key='df', mode='r')\n",
    "X_bpw, y , groups = X_bpw.reset_index(drop = True) , y.reset_index(drop = True) , groups.reset_index(drop = True)\n",
    "\n",
    "X_max_freqs = pd.read_hdf(load_path_max_freqs + data_type +  'six_second_max_freq_stats_df.h5', key='df', mode='r')\n",
    "X_max_freqs = X_max_freqs.reset_index(drop = True)\n",
    "\n",
    "X = pd.concat([X_bpw , X_max_freqs], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5000b824-6f96-4c71-9a57-fa2b8c1cc207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the X into TS_Fresh Features___\n",
    "# 1. Convert to TS_Fresh format Dataframe \n",
    "ts_fresh_df = format_eeg_data.convert_sktime_df_to_ts_fresh_format(X, ts_cols = list(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5530bacb-2238-4657-9ab5-27665bfa355f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17-Nov-23 18:11:04 | WARNING | Dependency not available for matrix_profile, this feature will be disabled!\n"
     ]
    }
   ],
   "source": [
    "# 2. Extract TS_Fresh Features from the dataframe\n",
    "if TS_Fresh_setting == 'Minimal':\n",
    "    settings = MinimalFCParameters()\n",
    "elif TS_Fresh_setting == 'Efficient':\n",
    "    settings = EfficientFCParameters()\n",
    "else:\n",
    "    raise Exception('No TS Fresh Parameter Setting Set!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e32e28e-a07b-4d0f-b2fd-e7a4f10e4af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 120/120 [00:02<00:00, 46.81it/s]\n"
     ]
    }
   ],
   "source": [
    "extracted_ts_fresh_df = extract_features(ts_fresh_df, column_id = 'id' , column_sort = 'time',  default_fc_parameters=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a77fd7ac-5fdf-4d67-9312-b1ecbd4e21ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1950\n",
      "1950\n"
     ]
    }
   ],
   "source": [
    "# 3. Asign extract_ts_fresh_df to the variable X\n",
    "X = extracted_ts_fresh_df.copy()\n",
    "print(len(X.columns))\n",
    "#Drop columns where all values are NA \n",
    "X = X.dropna(axis = 1)\n",
    "print(len(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "499d61d3-2afe-4f3a-b5f6-aae9db4aa8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1950\n"
     ]
    }
   ],
   "source": [
    "#Drop columns where all values are the same\n",
    "# Find columns where all values are the same\n",
    "same_value_columns = X.columns[X.nunique() == 1]\n",
    "# Drop columns with the same values\n",
    "X = X.drop(columns=same_value_columns)\n",
    "print(len(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc4bd4e9-0b7d-4268-8e18-8b615d34bfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a region to features dictionary - this will enable us to run expts regionally as before\n",
    "regional_features_dict = {}\n",
    "region_channel_dict = constants.region_to_channel_dict\n",
    "regions = list(region_channel_dict.keys())\n",
    "\n",
    "for region in regions:\n",
    "    region_features = [col for col in X.columns if region + '_' in col]\n",
    "    regional_features_dict[region] = region_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f736b0ca-a3f2-49f6-9120-75db43cce8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.Generate expt specific X,y,groups\n",
    "X_expt , y_expt , groups_expt, expt_info = run_expts.generate_expt_x_y_groups(X,y,groups, expt_num )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd6cedeb-c7e8-4d28-a9a3-30b33af43201",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example CLf\n",
    "#I need to edit this to loop through classifiers imho \n",
    "clf_dict = {'DT' : DecisionTreeClassifier(random_state = 5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c9c52c4-877d-4c17-990c-a8117575fe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = run_expts.run_mv_tsc(X_expt,y_expt,groups_expt,  clf_dict , return_df = True , subset_names_and_cols = regional_features_dict, random_states = [1,2] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
