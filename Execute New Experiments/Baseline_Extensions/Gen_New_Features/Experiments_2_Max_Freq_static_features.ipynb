{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39fafc11-b958-4a06-b2f7-ce0d114a911b",
   "metadata": {},
   "source": [
    "Purpose of this notebook is to run static experiments on Max Frequency Statistics for all data types and experiment types <br>\n",
    "Would like to save the results so this notebook can easily be re-run by loading results and without re-running the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8a5d176-9e8b-420d-8054-bb7c71892a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/home/ko20929/.conda/envs/sktime_latest/lib/python3.11/site-packages/antropy/fractal.py:197: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit((types.Array(types.float64, 1, \"C\", readonly=True), types.int32))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mne as mne\n",
    "import os \n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import constants\n",
    "from IPython.utils import io\n",
    "import time\n",
    "import sys\n",
    "import yasa\n",
    "from scipy.signal import welch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#Import my modules\n",
    "import format_eeg_data\n",
    "import constants\n",
    "import eeg_stat_ts\n",
    "import run_expts\n",
    "\n",
    "# Set display options to show all rows and columns\n",
    "pd.set_option('display.max_rows', 50)  # Show rows\n",
    "pd.set_option('display.max_columns', 160)  # Show columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "966398fd-c392-4041-9882-5439dde7244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_path = '/user/home/ko20929/work/RBD_using_custom_package/Execute New Experiments/Baseline_Extensions/Gen_New_Features/generated_feats/'\n",
    "data_types = ['Wake','N1', 'N2', 'N3', 'REM']\n",
    "\n",
    "loaded_data = {}\n",
    "\n",
    "for data_type in data_types:\n",
    "    X_y_groups = {}\n",
    "    \n",
    "    load_path = core_path + data_type\n",
    "    X = pd.read_hdf(load_path + 'six_second_max_freq_stats_df.h5', key='df', mode='r')\n",
    "    y = pd.read_hdf(load_path + '_y.h5', key='df', mode='r') \n",
    "    groups = pd.read_hdf(load_path + '_groups.h5', key='df', mode='r')  \n",
    "    \n",
    "    # Replace time sereis data with mean of the data ______________________________________________________________________________________________________\n",
    "\n",
    "    # Defining a function to replace time series of values with their mean\n",
    "    def function(x):\n",
    "        return x.values.mean()\n",
    "        \n",
    "    #Construct the static features\n",
    "    static_features_df = X.apply(np.vectorize(function))\n",
    "    X = static_features_df.copy()\n",
    "\n",
    "    X_y_groups['X'] = X\n",
    "    X_y_groups['y'] = y\n",
    "    X_y_groups['groups'] = groups\n",
    "    \n",
    "    loaded_data[data_type] = X_y_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596c4618-0e5c-46a9-b71e-226f0b71ecf4",
   "metadata": {},
   "source": [
    "### Generate Dicts required for Expts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df5f5095-b0fb-46c7-a3e7-5f4a0b00d257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. #Generate region to features dictionary to enable experiments to be run regionally\n",
    "regional_features_dict = {}\n",
    "region_channel_dict = constants.region_to_channel_dict\n",
    "regions = list(region_channel_dict.keys())\n",
    "for region in regions:\n",
    "    region_features = [col for col in X.columns if '_' + region in col]\n",
    "    if len(region_features) > 0 : \n",
    "        regional_features_dict[region] = region_features\n",
    "\n",
    "# 2. #Create the combined regions dictionary\n",
    "regions = list(regional_features_dict.keys())\n",
    "combined_regions_features_dict = {}\n",
    "    \n",
    "for i, region_1 in enumerate(regions):\n",
    "    for region_2 in regions[i+1:]:\n",
    "        new_key = region_1 + '_' + region_2\n",
    "        combined_regions_features_dict[new_key] = regional_features_dict[region_1] + regional_features_dict[region_2]\n",
    "\n",
    "#3. Use all of the features\n",
    "all_data_dict = {'All_regions' : list(X.columns) , 'All_regions_2' : list(X.columns)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3c8ec5-822d-4cc0-8f72-a046fe29dd23",
   "metadata": {},
   "source": [
    "### Experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d9ad21-ea7b-4e79-b295-bbe8b7fa93f8",
   "metadata": {},
   "source": [
    "{ 1 : { 'N1' : {'regional' : results_df_regional , 'regions_combined' : results_df_regions_combined , 'all_feats' : results_df_all_feats} , 'N2' : {} } , 2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4011c499-22ab-4048-b74e-a6af213a19c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2758.0393917560577"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run Experiments 1-4\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "all_expt_results = {}\n",
    "\n",
    "for expt_num in [1,2,3,4] :\n",
    "    expt_results = {}\n",
    "    for data_type in data_types:\n",
    "        X_y_groups = loaded_data[data_type]\n",
    "        \n",
    "        X = X_y_groups['X']\n",
    "        y = X_y_groups['y'] \n",
    "        groups = X_y_groups['groups'] \n",
    "            \n",
    "        #1.Generate expt specific X,y,groups\n",
    "        X_expt , y_expt , groups_expt, expt_info = run_expts.generate_expt_x_y_groups(X,y,groups, expt_num )\n",
    "    \n",
    "        results_df_regional = run_expts.run_mv_tsc(X_expt,y_expt,groups_expt,  {'RF' : RandomForestClassifier(random_state = 5) , 'DT' : DecisionTreeClassifier() , 'Ada_B' : AdaBoostClassifier(random_state = 5)} , return_df = True , subset_names_and_cols = regional_features_dict, random_states = [1,2] )\n",
    "        results_df_regions_combined = run_expts.run_mv_tsc(X_expt,y_expt,groups_expt,  {'RF' : RandomForestClassifier(random_state = 5) , 'DT' : DecisionTreeClassifier() , 'Ada_B' : AdaBoostClassifier(random_state = 5)} , return_df = True , subset_names_and_cols = combined_regions_features_dict, random_states = [1,2] )\n",
    "        results_df_all_feats = run_expts.run_mv_tsc(X_expt,y_expt,groups_expt,  {'RF' : RandomForestClassifier(random_state = 5) , 'DT' : DecisionTreeClassifier() , 'Ada_B' : AdaBoostClassifier(random_state = 5)} , return_df = True , subset_names_and_cols = all_data_dict, random_states = [1,2] )\n",
    "        \n",
    "        expt_results[data_type] = {'regional' : results_df_regional , 'regions_combined' : results_df_regions_combined , 'all_feats' : results_df_all_feats}\n",
    "    \n",
    "    all_expt_results[expt_num] = expt_results\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "t2-t1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0517c3d-2289-4ee2-9cd2-92a996fbe407",
   "metadata": {},
   "source": [
    "### Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7927d7b-6645-46e4-a92e-2a63ec8f2657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['static_frequency_feats_results.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving Results \n",
    "joblib.dump(all_expt_results, 'static_frequency_feats_results.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece8feca-1c38-4ceb-b0ad-f4767fdc9eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the results\n",
    "results = joblib.load('static_frequency_feats_results.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa425436-b67e-41e3-9109-52d393083fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.9673231959343"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2758.0393917560577/60"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
