{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75ba0cf1-621c-47f0-bdcb-11a82411ce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Will begin with EC data as a test since the other freq expt did well on that and it has lowest computational cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f68eb09f-60c6-4289-afd8-16a852e43193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/home/ko20929/.conda/envs/sktime_latest/lib/python3.11/site-packages/antropy/fractal.py:197: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit((types.Array(types.float64, 1, \"C\", readonly=True), types.int32))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mne as mne\n",
    "import os \n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import constants\n",
    "from IPython.utils import io\n",
    "import time\n",
    "import sys\n",
    "import yasa\n",
    "from scipy.signal import welch\n",
    "\n",
    "#Import my modules\n",
    "import format_eeg_data\n",
    "import constants\n",
    "import eeg_stat_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09de4d4c-70d2-4029-836f-205ce66d6fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_67738/904360650.py:74: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->Index(['First_Max_Value_Central', 'First_Max_Freq_Central',\n",
      "       'Second_Max_Value_Central', 'Second_Max_Freq_Central',\n",
      "       'Third_Max_Value_Central', 'Third_Max_Freq_Central',\n",
      "       'Fourth_Max_Value_Central', 'Fourth_Max_Freq_Central',\n",
      "       'First_Max_Value_Frontal', 'First_Max_Freq_Frontal',\n",
      "       ...\n",
      "       'Fourth_Max_Value_Right Parietal', 'Fourth_Max_Freq_Right Parietal',\n",
      "       'First_Max_Value_Right Temporal', 'First_Max_Freq_Right Temporal',\n",
      "       'Second_Max_Value_Right Temporal', 'Second_Max_Freq_Right Temporal',\n",
      "       'Third_Max_Value_Right Temporal', 'Third_Max_Freq_Right Temporal',\n",
      "       'Fourth_Max_Value_Right Temporal', 'Fourth_Max_Freq_Right Temporal'],\n",
      "      dtype='object', length=104)]\n",
      "\n",
      "  ts_df.to_hdf(folder + data_type + 'six_second_max_freq_stats_df.h5' , key = 'df', mode = 'w')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for REM !....\n",
      "883.6936159133911\n",
      "N1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_67738/904360650.py:74: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->Index(['First_Max_Value_Central', 'First_Max_Freq_Central',\n",
      "       'Second_Max_Value_Central', 'Second_Max_Freq_Central',\n",
      "       'Third_Max_Value_Central', 'Third_Max_Freq_Central',\n",
      "       'Fourth_Max_Value_Central', 'Fourth_Max_Freq_Central',\n",
      "       'First_Max_Value_Frontal', 'First_Max_Freq_Frontal',\n",
      "       ...\n",
      "       'Fourth_Max_Value_Right Parietal', 'Fourth_Max_Freq_Right Parietal',\n",
      "       'First_Max_Value_Right Temporal', 'First_Max_Freq_Right Temporal',\n",
      "       'Second_Max_Value_Right Temporal', 'Second_Max_Freq_Right Temporal',\n",
      "       'Third_Max_Value_Right Temporal', 'Third_Max_Freq_Right Temporal',\n",
      "       'Fourth_Max_Value_Right Temporal', 'Fourth_Max_Freq_Right Temporal'],\n",
      "      dtype='object', length=104)]\n",
      "\n",
      "  ts_df.to_hdf(folder + data_type + 'six_second_max_freq_stats_df.h5' , key = 'df', mode = 'w')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for N1 !....\n",
      "296.70962357521057\n",
      "N2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_67738/904360650.py:74: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->Index(['First_Max_Value_Central', 'First_Max_Freq_Central',\n",
      "       'Second_Max_Value_Central', 'Second_Max_Freq_Central',\n",
      "       'Third_Max_Value_Central', 'Third_Max_Freq_Central',\n",
      "       'Fourth_Max_Value_Central', 'Fourth_Max_Freq_Central',\n",
      "       'First_Max_Value_Frontal', 'First_Max_Freq_Frontal',\n",
      "       ...\n",
      "       'Fourth_Max_Value_Right Parietal', 'Fourth_Max_Freq_Right Parietal',\n",
      "       'First_Max_Value_Right Temporal', 'First_Max_Freq_Right Temporal',\n",
      "       'Second_Max_Value_Right Temporal', 'Second_Max_Freq_Right Temporal',\n",
      "       'Third_Max_Value_Right Temporal', 'Third_Max_Freq_Right Temporal',\n",
      "       'Fourth_Max_Value_Right Temporal', 'Fourth_Max_Freq_Right Temporal'],\n",
      "      dtype='object', length=104)]\n",
      "\n",
      "  ts_df.to_hdf(folder + data_type + 'six_second_max_freq_stats_df.h5' , key = 'df', mode = 'w')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for N2 !....\n",
      "2875.510270357132\n",
      "N3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_67738/904360650.py:74: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->Index(['First_Max_Value_Central', 'First_Max_Freq_Central',\n",
      "       'Second_Max_Value_Central', 'Second_Max_Freq_Central',\n",
      "       'Third_Max_Value_Central', 'Third_Max_Freq_Central',\n",
      "       'Fourth_Max_Value_Central', 'Fourth_Max_Freq_Central',\n",
      "       'First_Max_Value_Frontal', 'First_Max_Freq_Frontal',\n",
      "       ...\n",
      "       'Fourth_Max_Value_Right Parietal', 'Fourth_Max_Freq_Right Parietal',\n",
      "       'First_Max_Value_Right Temporal', 'First_Max_Freq_Right Temporal',\n",
      "       'Second_Max_Value_Right Temporal', 'Second_Max_Freq_Right Temporal',\n",
      "       'Third_Max_Value_Right Temporal', 'Third_Max_Freq_Right Temporal',\n",
      "       'Fourth_Max_Value_Right Temporal', 'Fourth_Max_Freq_Right Temporal'],\n",
      "      dtype='object', length=104)]\n",
      "\n",
      "  ts_df.to_hdf(folder + data_type + 'six_second_max_freq_stats_df.h5' , key = 'df', mode = 'w')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for N3 !....\n",
      "1519.4735362529755\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "channels = constants.channel_list\n",
    "data_types = ['N2', 'N3','REM', 'Wake', 'N1']\n",
    "\n",
    "for data_type in ['REM', 'N1', 'N2', 'N3']:   \n",
    "    \n",
    "\n",
    "    print(data_type)\n",
    "    \n",
    "    \n",
    "    t1 = time.time()\n",
    "    \n",
    "    paths , class_list, sleep_night_list , sleep_type_list , participant_id_list = constants.generate_paths_and_info(blue_pebble = True)\n",
    "    \n",
    "    selected_paths , s_class_list , s_night_list , s_sleep_type , s_p_id = [], [], [], [], []\n",
    "\n",
    "    for path , class_name, night , p_id in zip(paths, class_list, sleep_night_list, participant_id_list ):\n",
    "        if data_type in path:\n",
    "            selected_paths.append(path) \n",
    "            s_class_list.append(class_name)\n",
    "            s_night_list.append(night)\n",
    "            s_sleep_type.append(data_type)\n",
    "            s_p_id.append(p_id)\n",
    "\n",
    "    #2. Load corresponding data into dataframes , store in dataframe list\n",
    "    df_list = []\n",
    "    error_paths = []\n",
    "    with io.capture_output() as captured:\n",
    "        for path in selected_paths:\n",
    "            try:\n",
    "                data_epo = mne.read_epochs(path)\n",
    "                data = data_epo._data * 1e6  # convert signal from V to uV\n",
    "                df_full = data_epo.to_data_frame()\n",
    "                df = df_full[channels].copy()\n",
    "                df_list.append(df)\n",
    "            except:\n",
    "                error_paths.append(path)\n",
    "    \n",
    "    #Remove paths with errors from lists \n",
    "    for path in error_paths:\n",
    "        path_index = selected_paths.index(path)\n",
    "        #pop that index from all lists\n",
    "        selected_paths.pop(path_index) \n",
    "        s_class_list.pop(path_index)\n",
    "        s_night_list.pop(path_index)\n",
    "        s_sleep_type.pop(path_index)\n",
    "        s_p_id.pop(path_index)\n",
    "        \n",
    "    #Now we have the 57 channel EEG data in df's in df_list and corresponding supplementary information in the lists \n",
    "    #Selected_paths , s_class_list , s_night_list , s_sleep_type , s_p_id\n",
    "\n",
    "    #Convert each dataframe of raw chanel EEG data into a single row of TS data , with bpw statistics calculated per region\n",
    "    # Store each row in ts_row_list\n",
    "    ts_row_list = []\n",
    "\n",
    "    for df in df_list:\n",
    "        #1.Generate the window indices \n",
    "        window_indices = eeg_stat_ts.gen_window_indices(6, df , samp_freq = 256)\n",
    "        #2. Calculate max freq stats per window\n",
    "        max_freqs__per_win_df = eeg_stat_ts.gen_statistic_per_window(df , window_indices , stat = 'max_psd_stats')\n",
    "        #3. Convert bpw per window per channel into bpw per window per region\n",
    "        regional_df = eeg_stat_ts.convert_chan_stats_to_region(max_freqs__per_win_df, constants.channel_list , constants.region_to_channel_dict, average_type = 'mean')\n",
    "        #4. Convert into a single row of a new dataframe where each cell is a series\n",
    "        new_row = eeg_stat_ts.dataframe_to_ts_row(regional_df, list(regional_df.columns[:-1]) )\n",
    "        ts_row_list.append(new_row)\n",
    "        \n",
    "    # Save everything in the appropriate place ---->  final_transformed_df, groups , y\n",
    "    folder = '/user/home/ko20929/work/RBD_using_custom_package/Execute New Experiments/Baseline_Extensions/Gen_New_Features/generated_feats/'\n",
    "    \n",
    "    ts_df = pd.DataFrame.from_records(ts_row_list)\n",
    "    groups = pd.Series(s_p_id)\n",
    "    s_class_list = pd.Series(s_class_list)\n",
    "    y = s_class_list.map({'HC': 0 , 'PD' : 1 , 'PD+RBD' : 2 , 'RBD' : 3})\n",
    "\n",
    "    ts_df.to_hdf(folder + data_type + 'six_second_max_freq_stats_df.h5' , key = 'df', mode = 'w')\n",
    "    groups.to_hdf(folder + data_type + '_groups.h5' , key = 'df', mode = 'w')\n",
    "    y.to_hdf(folder + data_type + '_y.h5' , key = 'df', mode = 'w')\n",
    "    print('Done for ' + data_type + ' !....')\n",
    "    \n",
    "    t2 = time.time()\n",
    "    \n",
    "    print(t2 - t1)\n",
    "\n",
    "print(error_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d471f446-76d8-4c96-aa42-bb54f4c381f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
