{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd34f7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/sphere/ebirah/ko20929/miniconda3/envs/sktime_latest/lib/python3.11/site-packages/antropy/fractal.py:197: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @jit((types.Array(types.float64, 1, \"C\", readonly=True), types.int32))\n"
     ]
    }
   ],
   "source": [
    "from IPython.utils import io\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "import joblib\n",
    "from os.path import exists\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import mne\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#From my EEG package \n",
    "import run_expts\n",
    "import format_eeg_data\n",
    "import constants\n",
    "import eeg_stat_ts\n",
    "\n",
    "from sktime.transformations.panel.catch22 import Catch22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a114251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import custom_ts_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aae70a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This notebook is being created by editing the gen_c_22_features.py script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1bf1e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['DN_HistogramMode_5', 'DN_HistogramMode_10', 'SB_BinaryStats_diff_longstretch0', 'DN_OutlierInclude_p_001_mdrmd', 'DN_OutlierInclude_n_001_mdrmd', \n",
    " 'CO_f1ecac', 'CO_FirstMin_ac', 'SP_Summaries_welch_rect_area_5_1', 'SP_Summaries_welch_rect_centroid', 'FC_LocalSimple_mean3_stderr', 'CO_trev_1_num', \n",
    " 'CO_HistogramAMI_even_2_5', 'IN_AutoMutualInfoStats_40_gaussian_fmmi', 'MD_hrv_classic_pnn40', 'SB_BinaryStats_mean_longstretch1', 'SB_MotifThree_quantile_hh',\n",
    " 'FC_LocalSimple_mean1_tauresrat', 'CO_Embed2_Dist_tau_d_expfit_meandiff', 'SC_FluctAnal_2_dfa_50_1_2_logi_prop_r1', 'SC_FluctAnal_2_rsrangefit_50_1_logi_prop_r1', \n",
    " 'SB_TransitionMatrix_3ac_sumdiagcov', 'PD_PeriodicityWang_th0_01' , 'StandardDeviation' , 'Mean']\n",
    "\n",
    "transformer = Catch22(features = feature_list , catch24 = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb4534bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    path_num = int(sys.argv[1]) #This will be input to the script\n",
    "except:\n",
    "    path_num = 2\n",
    "\n",
    "data_types = {'Wake' : 56 , 'N1' : 71 , 'N2' : 71, 'N3' : 72} #I think this will be handled by the input to the script\n",
    "#The BP array \n",
    "\n",
    "data_type = 'N2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c4a2d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = constants.channel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ac9f249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /export/sphere/ebirah/ko20929/RBD_files/All_data/N2_data/HC_1102_Night 2_N2.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_959840/441940523.py:21: RuntimeWarning: This filename (/export/sphere/ebirah/ko20929/RBD_files/All_data/N2_data/HC_1102_Night 2_N2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  data_epo = mne.read_epochs(selected_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =       0.00 ...   29996.09 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "296 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'transformed_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 43\u001b[0m\n\u001b[1;32m     35\u001b[0m eeg_data_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_records(ts_row_list)\n\u001b[1;32m     37\u001b[0m  \u001b[38;5;66;03m#4. Transform the dataframe _______________________________________________________________________________________\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# transformed_df = transformer.fit_transform(eeg_data_df)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#Rename columns ..... I would say do this in a seperate script after the processing of all of them has been done\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Save the transformed_df \u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m transformed_df\u001b[38;5;241m.\u001b[39mto_hdf(\u001b[38;5;28mstr\u001b[39m(path_num) \u001b[38;5;241m+\u001b[39m data_type \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_c_22_features.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf\u001b[39m\u001b[38;5;124m'\u001b[39m, mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transformed_df' is not defined"
     ]
    }
   ],
   "source": [
    "# data type is one of ---> ['REM', 'N1', 'N2', 'N3', 'Wake']\n",
    "#First you have to load the saved paths \n",
    "try:\n",
    "    paths_dict = joblib.load(data_type + '_paths.pkl')\n",
    "except: \n",
    "    paths_dict = joblib.load('paths_test.pkl')\n",
    "    \n",
    "#Then assign the lists to the appropriate variables\n",
    "selected_paths = paths_dict['selected_paths']\n",
    "s_class_list = paths_dict['s_class_list']\n",
    "s_night_list = paths_dict['s_night_list']\n",
    "s_sleep_type = paths_dict['s_sleep_type']\n",
    "s_p_id = paths_dict['s_p_id']\n",
    "\n",
    "#Now everything that was done for multiple paths is done for the one selected path (everything in parallel)\n",
    "#You really only need the path --> as oll supplementary info goes into groups , class_list and y \n",
    "\n",
    "selected_path = selected_paths[path_num]\n",
    "\n",
    "#2.Load corresponding data into dataframe, df \n",
    "data_epo = mne.read_epochs(selected_path)\n",
    "data = data_epo._data * 1e6  # convert signal from V to uV\n",
    "df_full = data_epo.to_data_frame()\n",
    "df = df_full[channels].copy()\n",
    "\n",
    "#3.Load all of the data into a single dataframe with each cell containing a time series\n",
    "ts_row_list = []\n",
    "row = {}\n",
    "for col in df.columns:\n",
    "    row[col] = df[col]\n",
    "ts_row_list.append(row)\n",
    "\n",
    "#Create dataframe from that single row (previously was dataframe from multiple rows)____________________________________\n",
    "#All of the main pieces of data to save \n",
    "eeg_data_df = pd.DataFrame.from_records(ts_row_list)\n",
    "#Trims down to 45 minutes worth of data\n",
    "eeg_data_df = custom_ts_length.customise_df_ts_length(eeg_data_df,691200 , impute = False ) \n",
    "\n",
    "\n",
    " #4. Transform the dataframe _______________________________________________________________________________________\n",
    "# transformed_df = transformer.fit_transform(eeg_data_df)\n",
    "\n",
    "# Save the transformed_df \n",
    "transformed_df.to_hdf(str(path_num) + data_type + '_c_22_features.h5', key = 'df', mode = 'w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
