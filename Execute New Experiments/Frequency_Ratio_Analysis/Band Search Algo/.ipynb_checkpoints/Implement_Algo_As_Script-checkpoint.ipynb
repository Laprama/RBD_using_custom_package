{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82bb391b-f47c-4256-9271-650d7a344a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/home/ko20929/.conda/envs/sktime_latest/lib/python3.11/site-packages/antropy/fractal.py:197: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit((types.Array(types.float64, 1, \"C\", readonly=True), types.int32))\n",
      "/user/home/ko20929/.conda/envs/sktime_latest/lib/python3.11/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package yasa is out of date. Your version is 0.6.3, the latest is 0.6.4.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mne as mne\n",
    "import os \n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import constants\n",
    "from IPython.utils import io\n",
    "import time\n",
    "import sys\n",
    "import yasa\n",
    "from scipy.signal import welch\n",
    "from constants import regions\n",
    "\n",
    "#Import my modules\n",
    "import format_eeg_data\n",
    "import constants\n",
    "import eeg_stat_ts\n",
    "import run_expts\n",
    "\n",
    "#Import sklearn modules\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c2f2ae-b303-4b1a-8a1b-ada8a3ac7ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the functions that I will use (paste them from the another notebook\n",
    "\n",
    "## Comment out the bottom two lines\n",
    "sys.argv[1] = 1\n",
    "sys.argv[2] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97f62d0d-2a8c-4fef-95a5-8c9649f685ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_type_num defines the data type using an integer 0,1,2,3, or 4 \n",
    "d_type_num = int(sys.argv[1])\n",
    "data_type = ['Wake', 'N1', 'N2', 'N3','REM'][d_type_num]\n",
    "\n",
    "expt_num = int(sys.argv[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b033a4c-4c78-43f7-b342-1415616a388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "reduced_slide_list = [ (0.5, 0.5), (1, 0.5), (2, 0.5), (3, 0.5), (4, 0.5), (6, 0.5), (8, 0.5), (10, 1), (12, 1), (14, 1)]\n",
    "super_reduced_slide_list = [ (0.5, 0.5), (1, 0.5), (2, 0.5), (4, 1), (6, 1), (8, 1), (10,1), (14, 1) ] \n",
    "\n",
    "\n",
    "\n",
    "#2. Load the data based on data type ___________________________________________________________\n",
    "df = pd.read_hdf(os.path.join(os.path.abspath('..'),'Multiple_PSDs_Per_Participant/' + data_type + 'processed_multiple_psds_per_person.h5') , key = 'df')\n",
    "\n",
    "y = df['y'].copy()\n",
    "groups = df['groups'].copy()\n",
    "\n",
    "df = df.drop(columns = ['groups', 'y'])\n",
    "\n",
    "regional_dfs = {}\n",
    "\n",
    "for region in regions:\n",
    "    \n",
    "    single_region_df = df[[col for col in df.columns if col.endswith('_' + region)]]\n",
    "    frequency_vals  = np.arange(0.5,40.125, 0.125)\n",
    "    single_region_df.columns = frequency_vals\n",
    "    \n",
    "    folder = '/user/home/ko20929/work/RBD_using_custom_package/Blue_pebble/'\n",
    "    # paths = joblib.load(folder + data_type + '_paths.pkl')\n",
    "    \n",
    "    # groups = pd.Series(paths['s_p_id'])\n",
    "    # s_class_list = pd.Series(paths['s_class_list'])\n",
    "    # y = s_class_list.map({'HC': 0 , 'PD' : 1 , 'PD+RBD' : 2 , 'RBD' : 3})\n",
    "    \n",
    "    #3 Generate the frequency band search space ____________________________________________________\n",
    "    width_slide_list = [(0.5,0.5)] \n",
    "    for window_width in range(1, 15 ):\n",
    "        width_slide_list.append((window_width, 0.5) )\n",
    "    \n",
    "    #4 Calculate all of the features ________________________________________________________________\n",
    "    feature_dfs = []\n",
    "    \n",
    "    for window_width_hz, window_slide_hz in super_reduced_slide_list:\n",
    "        description = 'window width : ' + str(window_width_hz) + ' .  window stride : ' + str(window_slide_hz)\n",
    "        \n",
    "        #1.Set Window width in Hz and Window Slide in Hz\n",
    "        # window_width_hz = 3\n",
    "        window_len = (window_width_hz/0.125)+1\n",
    "        assert window_len%1 == 0\n",
    "        window_len = int(window_len)\n",
    "        \n",
    "        # window_slide_hz = 0.5 \n",
    "        window_slide_len = window_slide_hz/0.125 \n",
    "        assert window_slide_len%1 == 0\n",
    "        window_slide_len = int(window_slide_len)\n",
    "        \n",
    "        \n",
    "        #2.Calculate band values and store in dataframe calculated_df\n",
    "        \n",
    "        # Start of the window is the middle_freq value minus window_width_hz/2 \n",
    "        # End of the window is the middle freq value plus window_width_hz/2\n",
    "        window_len\n",
    "        \n",
    "        middle_freq = []\n",
    "        final_cols = []\n",
    "        \n",
    "        i = 0\n",
    "        while i < len(frequency_vals) - window_len:\n",
    "            middle_freq.append( frequency_vals[i:i+window_len].mean() )\n",
    "            band_vals = single_region_df.iloc[:,i:i+window_len].mean(axis = 1) #For every row calculate the mean for the appropriate elements\n",
    "            \n",
    "            final_cols.append(band_vals)\n",
    "            \n",
    "            # scaled_psd.append( psd_values[i:i+factor].mean() )\n",
    "            i+= window_slide_len\n",
    "        \n",
    "        calculated_df = pd.DataFrame(final_cols).T\n",
    "        calculated_df.columns = middle_freq\n",
    "        \n",
    "        calculated_df.columns = [ str(col) + '_width_' + str(window_width_hz) for col in calculated_df.columns]\n",
    "        \n",
    "        \n",
    "        #3.Calculate Information Gain Based on Features\n",
    "        #Change to binary HC vs PD / PD+RBD ---> Generate expt specific X,y,groups \n",
    "        X_expt , y_expt , groups_expt, expt_info = run_expts.generate_expt_x_y_groups(calculated_df,y,groups,expt_num)\n",
    "    \n",
    "        feature_dfs.append(X_expt)\n",
    "            \n",
    "    #5 Concatenate all feature_dfs into a single dataframe_________________________________________________________________\n",
    "    X_expt_concatenated = pd.concat(feature_dfs, axis=1)\n",
    "\n",
    "    #6 Calculate Frequency Ratio Columns\n",
    "    calculated_cols = []\n",
    "    col_names = []\n",
    "    \n",
    "    X_expt_ratios = X_expt_concatenated.copy() \n",
    "    \n",
    "    for col_1 in X_expt_concatenated.columns:\n",
    "        for col_2 in X_expt_concatenated.columns:\n",
    "            if col_1 == col_2:\n",
    "                pass\n",
    "            else:\n",
    "                new_col = col_1 + '/' + col_2  \n",
    "                col_names.append(new_col)\n",
    "                calculated_cols.append( X_expt_concatenated[col_1]/X_expt_concatenated[col_2] )\n",
    "    \n",
    "    df_ratios = pd.concat(calculated_cols, axis = 1)\n",
    "    df_ratios.columns = col_names\n",
    "    df_ratios_and_freq = pd.concat([df_ratios, X_expt_concatenated], axis = 1)\n",
    "    regional_dfs[region] = df_ratios_and_freq.copy()\n",
    "    print(region + 'done!')\n",
    "    t2 = time.time()\n",
    "    time_dif = t2 - t1\n",
    "    print(time_dif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aa2fe2-b77f-4ff0-b332-94a96d10f48c",
   "metadata": {},
   "source": [
    "#### Experiments loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab199cab-c3c2-49e1-96d8-4debf383ace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = groups_expt.copy()\n",
    "X = X_expt.copy()\n",
    "y = y_expt.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bbddd0-8b13-4ca8-be4c-fd0ab4d148fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in regions:\n",
    "    X_expt = regional_dfs[region]\n",
    "    X = X_expt.copy()\n",
    "    groups = groups_expt.copy()\n",
    "    y = y_expt.copy()\n",
    "\n",
    "\n",
    "    num = 1\n",
    "    gkf = GroupKFold(n_splits = 5) \n",
    "    pred_arrays = []\n",
    "    test_arrays = []\n",
    "    \n",
    "    for train_index, test_index  in gkf.split(X, y, groups = groups.astype(int)*num):\n",
    "                        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "                        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "                        #Fit model \n",
    "                        DT1, cols_used_in_DT1, DT2, cols_used_in_DT2 = fit_model(X_train, y_train , thresh = 0.9)\n",
    "                        \n",
    "                        #Make model predictions\n",
    "                        final_preds_array = model_predict(DT1, cols_used_in_DT1, DT2,cols_used_in_DT2, X_test, thresh = 0.9)\n",
    "    \n",
    "                        #Append pred arrays and test arrays to list \n",
    "                        pred_arrays.append(final_preds_array)\n",
    "                        test_arrays.append(y_test)\n",
    "                        print('done another juan ...!')\n",
    "    \n",
    "    \n",
    "    final_preds = np.concatenate(pred_arrays)\n",
    "    final_test = np.concatenate(test_arrays)\n",
    "    \n",
    "    correct_ratio , percent_preds_made = model_acc(final_preds, final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc56622b-16e7-4e73-9721-6da86acc3d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14371265, 0.99809292, 0.89597699, 0.76866771, 0.74530679,\n",
       "       0.29568417, 0.42567583, 0.01884471, 0.83698891, 0.85239958])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f31bc34-711a-4181-900c-de78af79540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "for region in regions:\n",
    "    results_dict[region] = {}\n",
    "    results_dict[region]['preds'] = np.random.rand(10) \n",
    "    results_dict[region]['test'] = np.random.rand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31ad160e-ce94-41ff-9152-241761ba2152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_results_dictionary.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(results_dict, 'test_results_dictionary.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "460283fc-09d7-4692-b891-4f41653f6157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Prefrontal': {'preds': array([0.6787853 , 0.60212086, 0.17663649, 0.4661643 , 0.77255717,\n",
       "         0.67274208, 0.29417726, 0.47232595, 0.39705857, 0.54070729]),\n",
       "  'test': array([0.47039858, 0.49903648, 0.2306049 , 0.32057108, 0.90686427,\n",
       "         0.95776997, 0.0043754 , 0.51401969, 0.14357803, 0.04094011])},\n",
       " 'Frontal': {'preds': array([0.65539544, 0.39043158, 0.11763664, 0.60416844, 0.48133576,\n",
       "         0.28055749, 0.75546095, 0.65184154, 0.44551991, 0.22187223]),\n",
       "  'test': array([0.15108675, 0.44458813, 0.65045314, 0.73266002, 0.43949984,\n",
       "         0.04896986, 0.372002  , 0.14719808, 0.78645783, 0.79068293])},\n",
       " 'Left Frontal': {'preds': array([0.75469605, 0.9706576 , 0.45984878, 0.94604433, 0.52647082,\n",
       "         0.4919449 , 0.34779677, 0.76345201, 0.47446961, 0.9745487 ]),\n",
       "  'test': array([0.47297537, 0.53963175, 0.40072497, 0.08923634, 0.66909952,\n",
       "         0.24984612, 0.6114832 , 0.65461352, 0.93380268, 0.26543658])},\n",
       " 'Right Frontal': {'preds': array([0.11940888, 0.42133589, 0.60393338, 0.29596503, 0.30214564,\n",
       "         0.16665879, 0.62856809, 0.67922402, 0.51901718, 0.88349113]),\n",
       "  'test': array([0.84289323, 0.11236066, 0.46063822, 0.8432975 , 0.82782303,\n",
       "         0.64911834, 0.57016695, 0.87334883, 0.25619565, 0.4189681 ])},\n",
       " 'Central': {'preds': array([0.83354049, 0.62446593, 0.99499576, 0.01234655, 0.16309389,\n",
       "         0.18910078, 0.96866017, 0.29515013, 0.6202454 , 0.94944447]),\n",
       "  'test': array([0.73433668, 0.79427888, 0.14843887, 0.89404535, 0.62860253,\n",
       "         0.0675254 , 0.08992067, 0.65507418, 0.64824893, 0.79943996])},\n",
       " 'Left Central': {'preds': array([0.17372512, 0.54660421, 0.1299594 , 0.18439772, 0.68625203,\n",
       "         0.78778947, 0.45041388, 0.12669774, 0.48569117, 0.5715474 ]),\n",
       "  'test': array([0.86954916, 0.09711923, 0.56027165, 0.63131146, 0.56486077,\n",
       "         0.56025658, 0.92127597, 0.22883863, 0.82640344, 0.86751926])},\n",
       " 'Right Central': {'preds': array([0.77130895, 0.63008742, 0.41111385, 0.30219636, 0.86005791,\n",
       "         0.21578552, 0.27911468, 0.78938044, 0.27624731, 0.7871589 ]),\n",
       "  'test': array([0.30187427, 0.42239449, 0.21569404, 0.832752  , 0.24184128,\n",
       "         0.01710766, 0.90702754, 0.75584962, 0.94884929, 0.66855132])},\n",
       " 'Left Temporal': {'preds': array([0.92404794, 0.07873673, 0.16025667, 0.25112836, 0.59432588,\n",
       "         0.49575678, 0.01303755, 0.32543485, 0.46579064, 0.58737788]),\n",
       "  'test': array([0.43878823, 0.813659  , 0.66371031, 0.46271405, 0.7429745 ,\n",
       "         0.24149703, 0.00699801, 0.30325078, 0.0944303 , 0.33873792])},\n",
       " 'Right Temporal': {'preds': array([0.23621537, 0.09923433, 0.98084254, 0.19851243, 0.35976876,\n",
       "         0.03255487, 0.53903526, 0.61100917, 0.78303695, 0.58202714]),\n",
       "  'test': array([0.58145971, 0.63708308, 0.2840689 , 0.68811629, 0.53571505,\n",
       "         0.1137772 , 0.10827925, 0.50886273, 0.5949045 , 0.20374432])},\n",
       " 'Parietal': {'preds': array([0.84838479, 0.3571209 , 0.95973745, 0.88213958, 0.14614117,\n",
       "         0.34287376, 0.6257651 , 0.36836105, 0.14811797, 0.10968343]),\n",
       "  'test': array([0.67950225, 0.19142126, 0.98753223, 0.95860622, 0.85251706,\n",
       "         0.69720677, 0.14795915, 0.1852567 , 0.70157087, 0.39132444])},\n",
       " 'Left Parietal': {'preds': array([0.29907087, 0.8493304 , 0.83559736, 0.20129983, 0.35474113,\n",
       "         0.50201129, 0.96474401, 0.09440594, 0.7563056 , 0.23357818]),\n",
       "  'test': array([0.72555749, 0.12967992, 0.80664816, 0.23634346, 0.96784738,\n",
       "         0.24761869, 0.39694551, 0.98860402, 0.43094042, 0.01842323])},\n",
       " 'Right Parietal': {'preds': array([0.51451696, 0.58862872, 0.34124047, 0.51912606, 0.30733954,\n",
       "         0.87234599, 0.89214065, 0.39091736, 0.75074733, 0.72152697]),\n",
       "  'test': array([0.21364933, 0.82400028, 0.76078993, 0.13001012, 0.64205558,\n",
       "         0.47912271, 0.82175328, 0.3276449 , 0.6383358 , 0.62095488])},\n",
       " 'Occipital': {'preds': array([0.9113907 , 0.92160124, 0.67345946, 0.26202538, 0.17511143,\n",
       "         0.68666047, 0.6313338 , 0.32515581, 0.96425613, 0.59022536]),\n",
       "  'test': array([0.91264252, 0.92293634, 0.3104232 , 0.80328177, 0.23830351,\n",
       "         0.26908994, 0.07949482, 0.99973131, 0.65117611, 0.28224159])}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.load('test_results_dictionary.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
