{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc29919-9f03-4c39-94b3-2b6ccfb4d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mne as mne\n",
    "import os \n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import constants\n",
    "from IPython.utils import io\n",
    "import time\n",
    "import sys\n",
    "import yasa\n",
    "from scipy.signal import welch\n",
    "\n",
    "## Use decision tree as a rough way for splitting based on that feature\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "\n",
    "#Import my modules\n",
    "import format_eeg_data\n",
    "import constants\n",
    "import eeg_stat_ts\n",
    "import run_expts\n",
    "\n",
    "from constants import regions\n",
    "\n",
    "# 1 Data type is defined by script input ______________________________________________________\n",
    "d_num = int( sys.argv[1] )\n",
    "data_type = ['N2', 'N3','REM', 'Wake', 'N1'][d_num]\n",
    "expt_num = int(sys.argv[2])\n",
    "\n",
    "\n",
    "for region in regions:\n",
    "    #2. Load the data based on data type ___________________________________________________________\n",
    "    df = joblib.load(os.path.join(os.path.abspath('..'), data_type + '_psd_normalised_data.pkl') )\n",
    "    \n",
    "    single_region_df = df[[col for col in df.columns if col.endswith('_' + region)]]\n",
    "    frequency_vals  = np.arange(0.5,40.125, 0.125)\n",
    "    single_region_df.columns = frequency_vals\n",
    "    \n",
    "    folder = '/user/home/ko20929/work/RBD_using_custom_package/Blue_pebble/'\n",
    "    paths = joblib.load(folder + data_type + '_paths.pkl')\n",
    "    \n",
    "    groups = pd.Series(paths['s_p_id'])\n",
    "    s_class_list = pd.Series(paths['s_class_list'])\n",
    "    y = s_class_list.map({'HC': 0 , 'PD' : 1 , 'PD+RBD' : 2 , 'RBD' : 3})\n",
    "    \n",
    "    #3 Generate the frequency band search space ____________________________________________________\n",
    "    width_slide_list = [(0.5,0.5)] \n",
    "    for window_width in range(1, 15 ):\n",
    "        width_slide_list.append((window_width, 0.5) )\n",
    "    \n",
    "    #4 Calculate all of the features ________________________________________________________________\n",
    "    feature_dfs = []\n",
    "    \n",
    "    for window_width_hz, window_slide_hz in width_slide_list:\n",
    "        description = 'window width : ' + str(window_width_hz) + ' .  window stride : ' + str(window_slide_hz)\n",
    "        \n",
    "        #1.Set Window width in Hz and Window Slide in Hz\n",
    "        # window_width_hz = 3\n",
    "        window_len = (window_width_hz/0.125)+1\n",
    "        assert window_len%1 == 0\n",
    "        window_len = int(window_len)\n",
    "        \n",
    "        # window_slide_hz = 0.5 \n",
    "        window_slide_len = window_slide_hz/0.125 \n",
    "        assert window_slide_len%1 == 0\n",
    "        window_slide_len = int(window_slide_len)\n",
    "        \n",
    "        \n",
    "        #2.Calculate band values and store in dataframe calculated_df\n",
    "        \n",
    "        # Start of the window is the middle_freq value minus window_width_hz/2 \n",
    "        # End of the window is the middle freq value plus window_width_hz/2\n",
    "        window_len\n",
    "        \n",
    "        middle_freq = []\n",
    "        final_cols = []\n",
    "        \n",
    "        i = 0\n",
    "        while i < len(frequency_vals) - window_len:\n",
    "            middle_freq.append( frequency_vals[i:i+window_len].mean() )\n",
    "            band_vals = single_region_df.iloc[:,i:i+window_len].mean(axis = 1) #For every row calculate the mean for the appropriate elements\n",
    "            \n",
    "            final_cols.append(band_vals)\n",
    "            \n",
    "            # scaled_psd.append( psd_values[i:i+factor].mean() )\n",
    "            i+= window_slide_len\n",
    "        \n",
    "        calculated_df = pd.DataFrame(final_cols).T\n",
    "        calculated_df.columns = middle_freq\n",
    "        \n",
    "        calculated_df.columns = [ str(col) + '_width_' + str(window_width_hz) for col in calculated_df.columns]\n",
    "        \n",
    "        \n",
    "        #3.Calculate Information Gain Based on Features\n",
    "        #Change to binary HC vs PD / PD+RBD ---> Generate expt specific X,y,groups \n",
    "        X_expt , y_expt , groups_expt, expt_info = run_expts.generate_expt_x_y_groups(calculated_df,y,groups,expt_num)\n",
    "    \n",
    "        feature_dfs.append(X_expt)\n",
    "            \n",
    "    #5 Concatenate all feature_dfs into a single dataframe_________________________________________________________________\n",
    "    X_expt_concatenated = pd.concat(feature_dfs, axis=1)\n",
    "    \n",
    "    #Edit from here downwards - \n",
    "    #1 Load the appropriate scores and column combos files\n",
    "    f_name =  'Results/' + data_type + '_' + region +  '_expt_' + str(expt_num) + '_scores.pkl'\n",
    "    scores = joblib.load(f_name)\n",
    "    \n",
    "    f_name =  'Results/' + data_type + '_' + region + '_expt_' + str(expt_num) + '_col_combos.pkl'\n",
    "    coL_combos = joblib.load(f_name)\n",
    "\n",
    "    #2. Determine the top n column combos\n",
    "    n = 1500\n",
    "    top_n_indices = list(np.argsort(np.array(scores))[-n:])\n",
    "    top_n_scores = np.array(scores)[top_n_indices]\n",
    "    \n",
    "    top_n_col_combos = np.array(col_combos)[top_n_indices]\n",
    "    top_n_col_combos = [list(val) for val in top_n_col_combos]\n",
    "\n",
    "    #3 Generate the reduced cols list \n",
    "    reduced_slide_list = [ (0.5, 0.5), (1, 0.5), (2, 0.5), (3, 0.5), (4, 0.5), (6, 0.5), (8, 0.5), (10, 1), (12, 1), (14, 1)]\n",
    "    reduced_cols_list = []\n",
    "    for window_width_hz, window_slide_hz in reduced_slide_list:\n",
    "        description = 'window width : ' + str(window_width_hz) + ' .  window stride : ' + str(window_slide_hz)\n",
    "            \n",
    "        #1.Set Window width in Hz and Window Slide in Hz\n",
    "        # window_width_hz = 3\n",
    "        window_len = (window_width_hz/0.125)+1\n",
    "        assert window_len%1 == 0\n",
    "        window_len = int(window_len)\n",
    "        \n",
    "        # window_slide_hz = 0.5 \n",
    "        window_slide_len = window_slide_hz/0.125 \n",
    "        assert window_slide_len%1 == 0\n",
    "        window_slide_len = int(window_slide_len)\n",
    "    \n",
    "        #2. Calculate band values and store in dataframe calculated_df\n",
    "        middle_freq = []\n",
    "    \n",
    "        i = 0\n",
    "    \n",
    "        while i < len(frequency_vals) - window_len:\n",
    "            middle_freq.append( frequency_vals[i:i+window_len].mean() )\n",
    "            # scaled_psd.append( psd_values[i:i+factor].mean() )\n",
    "            i+= window_slide_len\n",
    "    \n",
    "        cols_list = [str(col) + '_width_' + str(window_width_hz) for col in middle_freq]\n",
    "        reduced_cols_list += cols_list\n",
    "\n",
    "    #4. Create a new set of combos consisting of three cols\n",
    "    three_col_combos_list = []\n",
    "    for two_combo in top_n_col_combos:\n",
    "        for col in reduced_cols_list:\n",
    "            three_col = two_combo + [col]\n",
    "            three_col_combos_list.append(three_col)\n",
    "    \n",
    "    scores = []\n",
    "    for col_combo in three_col_combos_list: \n",
    "        X_selected = X_expt_concatenated[ col_combo ]\n",
    "        # clf = RidgeClassifier().fit(X_selected, y_expt)\n",
    "        clf = LinearDiscriminantAnalysis().fit(X_selected, y_expt)\n",
    "        score = accuracy_score(y_expt,  clf.predict(X_selected))\n",
    "        scores.append(score)\n",
    "    \n",
    "    f_name =  'Results/Three_Search/' + data_type + '_' + region +  '_expt_' + str(expt_num) + '_scores.pkl'\n",
    "    joblib.dump(scores,f_name)\n",
    "    \n",
    "    f_name =  'Results/Three_Search/' + data_type + '_' + region + '_expt_' + str(expt_num) + '_col_combos.pkl'\n",
    "    joblib.dump(three_col_combos_list,f_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
