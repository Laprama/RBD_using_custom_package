{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c50ef1cb-184f-4f5e-bcde-80551eb5cc27",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "690d6574-9615-4217-924d-6e7bb22c8118",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/home/ko20929/.conda/envs/sktime_latest/lib/python3.11/site-packages/antropy/fractal.py:197: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit((types.Array(types.float64, 1, \"C\", readonly=True), types.int32))\n",
      "/user/home/ko20929/.conda/envs/sktime_latest/lib/python3.11/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package yasa is out of date. Your version is 0.6.3, the latest is 0.6.4.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mne as mne\n",
    "import os \n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import constants\n",
    "from IPython.utils import io\n",
    "import time\n",
    "import sys\n",
    "import yasa\n",
    "from scipy.signal import welch\n",
    "\n",
    "#Import my modules\n",
    "import format_eeg_data\n",
    "import constants\n",
    "import eeg_stat_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b10ef03-bf72-4f5d-a064-8e79f71fc5cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Cross reference Wake P_Ids with other data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da882ecb-e964-43b2-a213-fb79d34baecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4411', '3305', '1114', '1115', '2201']\n",
      "['3306', '4404']\n"
     ]
    }
   ],
   "source": [
    "#1. Load Wake Data and work out which P_Id's are not there in other sleep data types. \n",
    "#These need to be dropped --> p_id_to_drop\n",
    "folder = '/user/home/ko20929/work/RBD_using_custom_package/Blue_pebble/'\n",
    "\n",
    "p_id_to_drop = []\n",
    "\n",
    "paths = joblib.load(folder + 'Wake' + '_paths.pkl')\n",
    "wake_groups = pd.Series(paths['s_p_id'])\n",
    "wake_groups_counts = wake_groups.value_counts()\n",
    "\n",
    "for ind, val in zip(wake_groups_counts.index, wake_groups_counts):\n",
    "    #loop through the groups of each data type\n",
    "    # print('Outer index is: ' + str(ind) ) for debugging\n",
    "    for data_type in ['N2', 'N3','REM', 'N1']:\n",
    "        paths = joblib.load(folder + data_type + '_paths.pkl')\n",
    "        groups = pd.Series(paths['s_p_id'])\n",
    " \n",
    "        if ind in groups.values: \n",
    "            pass \n",
    "        else:\n",
    "            #print(ind)\n",
    "            p_id_to_drop.append(ind)\n",
    "            wake_groups_counts = wake_groups_counts.drop(index = ind)\n",
    "            break\n",
    "\n",
    "print(p_id_to_drop)\n",
    "\n",
    "#2. Work Out which P_id's are present only once in other data types but twice in Wake \n",
    "#These need to be semi dropped --> single_pids\n",
    "\n",
    "wake_multiple_pids = wake_groups_counts[wake_groups_counts > 1]\n",
    "\n",
    "single_pids = []\n",
    "\n",
    "for ind, val in zip(wake_multiple_pids.index, wake_multiple_pids):\n",
    "    # For each p_id that has more than one value check if it has more than one record in other data types\n",
    "    \n",
    "    for data_type in ['N2', 'N3','REM', 'N1']:\n",
    "        paths = joblib.load(folder + data_type + '_paths.pkl')\n",
    "        groups = pd.Series(paths['s_p_id'])\n",
    "        group_counts = groups.value_counts()\n",
    "        \n",
    "        if group_counts[ind] > 1: \n",
    "            pass\n",
    "            \n",
    "        else:\n",
    "            single_pids.append(ind)\n",
    "            \n",
    "single_pids = list(np.unique(single_pids))\n",
    "\n",
    "print(single_pids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04968d3-f55a-4db9-afd0-c498fc932ff4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Load Wake Data , drop relevant p_ids (identified above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2fda3086-04bd-4449-a97f-01439bcdd42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load wake data _______________________________________________\n",
    "paths = joblib.load(folder + 'Wake' + '_paths.pkl')\n",
    "X = joblib.load('Wake_frequency_data.pkl')\n",
    "\n",
    "#Load groups and y labels _____________________________________\n",
    "groups = pd.Series(paths['s_p_id'])\n",
    "s_class_list = pd.Series(paths['s_class_list'])\n",
    "y = s_class_list.map({'HC': 0 , 'PD' : 1 , 'PD+RBD' : 2 , 'RBD' : 3}) \n",
    "\n",
    "#Drop p_ids that are not there in all other data types\n",
    "X['groups'] = groups \n",
    "X['y'] = y\n",
    "X = X[~X['groups'].isin(p_id_to_drop)]\n",
    "\n",
    "#Drop p_ids (two) that should only be present once\n",
    "for val in single_pids:\n",
    "    duplicates = X[X['groups'].duplicated(keep=False) & (X['groups'] == val)]\n",
    "    X = X.drop(duplicates.index[0])\n",
    "# X is what I want now, all features plus additional columns called 'groups' and 'y' \n",
    "X_wake = X.copy()\n",
    "\n",
    "X_wake.columns = [col + '_Wake' for col in X_wake.columns] #For joining with other data types later this is important\n",
    "\n",
    "#These P_ids have two values\n",
    "two_ind_vals = list(X_wake['groups_Wake'].value_counts()[ (X_wake['groups_Wake'].value_counts() > 1 ) ].index)\n",
    "two_ind_vals\n",
    "\n",
    "#X_wake contains all regional features AND groups + y columns. \n",
    "# X_wake has 49 rows \n",
    "\n",
    "#Sort the dataframe by p_id and reset the index\n",
    "X_wake = X_wake.sort_values(by = 'groups_Wake' , ascending = True)\n",
    "X_wake = X_wake.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2f549f-1b37-4671-8dd0-0b5b2c04c165",
   "metadata": {},
   "source": [
    "#### Join Non-Wake Data to Wake Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e0c55d01-35e9-4094-aad2-0b5514fc94b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/user/home/ko20929/work/RBD_using_custom_package/Blue_pebble/'\n",
    "\n",
    "#Concatenate all dataframes together to 'Concat_df'\n",
    "concat_df = X_wake.copy()\n",
    "\n",
    "for data_type in ['N1','N2','N3','REM']:\n",
    "\n",
    "    #1. Load the data - put features, groups and y labels into data frame X_df\n",
    "    X_df = joblib.load( data_type + '_frequency_data.pkl' )\n",
    "    paths = joblib.load(folder + data_type + '_paths.pkl')\n",
    "    \n",
    "    groups = pd.Series(paths['s_p_id'])\n",
    "    s_class_list = pd.Series(paths['s_class_list'])\n",
    "    y = s_class_list.map({'HC': 0 , 'PD' : 1 , 'PD+RBD' : 2 , 'RBD' : 3}) \n",
    "    \n",
    "    X_df['groups'] = groups \n",
    "    X_df['y'] = y\n",
    "\n",
    "    #2. Keep only the groups that are also present in Wake data\n",
    "    X_df_groups_reduced = X_df['groups'][X_df['groups'].isin(list(X_wake['groups_Wake'].values)) ]\n",
    "\n",
    "    #3. Drop those p_ids that are present more than they are in Wake data. E.g. once in wake data but twice here then drop one\n",
    "    matching_indices = [] #keep track of the indices to keep\n",
    "    series = X_df_groups_reduced\n",
    "    for val in np.unique(X_wake['groups_Wake']):\n",
    "        if val in two_ind_vals:\n",
    "            index_of_value = series[series == val].index[0]\n",
    "            matching_indices.append(index_of_value)\n",
    "            index_of_value = series[series == val].index[1]\n",
    "            matching_indices.append(index_of_value)\n",
    "            \n",
    "        else:\n",
    "            index_of_value = series[series == val].index[0]\n",
    "            matching_indices.append(index_of_value)\n",
    "        \n",
    "    if len(matching_indices) == 49:\n",
    "        pass\n",
    "    else: \n",
    "        print('something went wrong')\n",
    "        \n",
    "    X_df = X_df.loc[matching_indices]\n",
    "    X_df = X_df.sort_values(by = 'groups' , ascending = True)\n",
    "    X_df = X_df.reset_index(drop = True)\n",
    "    \n",
    "    # Append data_type to column name\n",
    "    X_df.columns = [col + '_' + data_type for col in X_df.columns]\n",
    "    \n",
    "    concat_df = pd.concat([concat_df, X_df], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d159833-c85c-45c8-a8a1-76d8c41c4a37",
   "metadata": {},
   "source": [
    "#### Check that Pid's match across data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0acc56fd-303c-43d5-a139-d0d30193bfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "data_types = ['Wake', 'N1','N2','N3','REM']\n",
    "cols_to_select = ['groups_' + data_type for data_type in data_types]\n",
    "print(concat_df[cols_to_select].nunique(axis = 1).eq(1).all())\n",
    "\n",
    "cols_to_select = ['y_' + data_type for data_type in data_types]\n",
    "print(concat_df[cols_to_select].nunique(axis = 1).eq(1).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb797ad-cb77-40a7-9b5e-61751fe61676",
   "metadata": {},
   "source": [
    "#### Save data as appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "600a9fa0-8261-482d-8871-8d350b0e94a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = concat_df['y_REM']\n",
    "groups = concat_df['groups_REM']\n",
    "data_types = ['Wake', 'N1','N2','N3','REM']\n",
    "cols_to_drop = ['groups_' + data_type for data_type in data_types] + ['y_' + data_type for data_type in data_types]\n",
    "concat_df = concat_df.drop(columns = cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "670fe23c-e659-4254-99ee-0deecfe6217f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['concat_df.pkl']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y , 'y_concat.pkl')\n",
    "joblib.dump(groups, 'groups_concat.pkl')\n",
    "joblib.dump(concat_df, 'concat_df.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
