{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74ca74d3-d27d-4926-8c42-e34dcce8da75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/home/ko20929/.conda/envs/sktime_latest/lib/python3.11/site-packages/antropy/fractal.py:197: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit((types.Array(types.float64, 1, \"C\", readonly=True), types.int32))\n",
      "/user/home/ko20929/.conda/envs/sktime_latest/lib/python3.11/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package yasa is out of date. Your version is 0.6.3, the latest is 0.6.4.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mne as mne\n",
    "import os \n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import constants\n",
    "from IPython.utils import io\n",
    "import time\n",
    "import sys\n",
    "import yasa\n",
    "from scipy.signal import welch\n",
    "import random\n",
    "\n",
    "from scipy.signal import ShortTimeFFT\n",
    "from scipy.signal.windows import gaussian\n",
    "\n",
    "#Import my modules\n",
    "import format_eeg_data\n",
    "import constants\n",
    "import eeg_stat_ts\n",
    "\n",
    "#Pytorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3a9356-8fa8-4790-931e-8aaefa821fe4",
   "metadata": {},
   "source": [
    "#### 1. Load the data - User inputs 'data_type' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f0e9f5e-c3c2-421e-8372-851846241e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potential to remove this and do processing in one go upfront then just load the data as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b549adfc-3aa8-4aac-9502-78cf33650edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = 'N1' # Remove this line for script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24171475-c47d-4717-bc8e-3ad64bca200e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.689120292663574"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "\n",
    "channels = constants.channel_list\n",
    "\n",
    "# 1. generate all path names and class list(s) etc. \n",
    "folder = '/user/home/ko20929/work/RBD_using_custom_package/Blue_pebble/'\n",
    "paths = joblib.load(folder + data_type + '_paths.pkl') # keys : ['selected_paths', 's_class_list', 's_night_list', 's_sleep_type', 's_p_id']\n",
    "\n",
    "# 2. Load corresponding data into dataframes, store in dataframe list\n",
    "df_list = []\n",
    "with io.capture_output() as captured:\n",
    "    for path in paths['selected_paths']:\n",
    "        data_epo = mne.read_epochs(path)\n",
    "        data = data_epo._data * 1e6  # convert signal from V to uV\n",
    "        df_full = data_epo.to_data_frame()\n",
    "        df = df_full[channels].copy()\n",
    "        \n",
    "        # Do z_score normalisation on the data\n",
    "        # Got it from here : https://www.geeksforgeeks.org/data-normalization-with-pandas/\n",
    "        # z_score normalisation __________________\n",
    "        # copy the data \n",
    "        df_z_scaled = df.copy() \n",
    "\n",
    "        # apply normalization techniques \n",
    "        for column in df_z_scaled.columns: \n",
    "            df_z_scaled[column] = (df_z_scaled[column] - df_z_scaled[column].mean()) / df_z_scaled[column].std()\n",
    "\n",
    "    \n",
    "        df_list.append(df_z_scaled)\n",
    "\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "t2-t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96c26e0d-17f8-42fa-b8b6-e3f719797578",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label_dict = {'HC': 0 , 'PD' : 1 , 'PD+RBD' : 2 , 'RBD' : 3} #Dictionary used to label the classes for reference\n",
    "y = np.array([class_label_dict[c_name] for c_name in paths['s_class_list'] ] )\n",
    "groups = paths['s_p_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "886ab606-ba83-4b15-ad66-6e3f9deb2367",
   "metadata": {},
   "outputs": [],
   "source": [
    "wake_dfs_binary = []\n",
    "y_binary = []\n",
    "groups_binary = []\n",
    "\n",
    "for df , class_label , group in zip(df_list, y, groups):\n",
    "    if class_label in [0,1]:\n",
    "        wake_dfs_binary.append(df)\n",
    "        y_binary.append(class_label)\n",
    "        groups_binary.append(group)\n",
    "\n",
    "y_binary = np.array(y_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590c9fe3-ed31-497c-8a62-a7b368837773",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
