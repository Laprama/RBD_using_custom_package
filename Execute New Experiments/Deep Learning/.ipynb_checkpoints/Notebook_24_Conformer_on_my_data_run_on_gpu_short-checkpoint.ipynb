{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14e0e248-2af5-435d-9467-11cd73dbb793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/home/ko20929/.conda/envs/sktime_latest/lib/python3.11/site-packages/antropy/fractal.py:197: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit((types.Array(types.float64, 1, \"C\", readonly=True), types.int32))\n",
      "/user/home/ko20929/.conda/envs/sktime_latest/lib/python3.11/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package yasa is out of date. Your version is 0.6.3, the latest is 0.6.5.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mne as mne\n",
    "import os \n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import constants\n",
    "from IPython.utils import io\n",
    "import time\n",
    "import sys\n",
    "import yasa\n",
    "from scipy.signal import welch\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "from scipy.signal import ShortTimeFFT\n",
    "from scipy.signal.windows import gaussian\n",
    "\n",
    "#Import my modules\n",
    "import format_eeg_data\n",
    "import constants\n",
    "import eeg_stat_ts\n",
    "\n",
    "#Pytorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "#Import Braindecode Model EEG Conformer\n",
    "from braindecode.models import EEGConformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2b786eb-3285-4eb3-ab83-e58163e5a1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuro_headset_channels = [\"AF3\", \"F7\", \"F3\", \"FC5\", \"T7\", \"P7\", \"O1\", \"O2\", \"P8\", \"T8\", \"FC6\", \"F4\", \"F8\", \"AF4\"]\n",
    "# These channels are equivalent to the neuro headset channels but for 'our' headset (There is code to generate these in notebook 18) \n",
    "eeg_14_channels = ['AF7', 'F7', 'F3', 'FC5', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF8']  \n",
    "\n",
    "num_channels = len(eeg_14_channels)\n",
    "num_channels\n",
    "\n",
    "# The below are currently in the script but need to be taken out to the top (here)\n",
    "segment_length = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3b6380-55b1-408d-839c-675b2a508193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N3\n",
      "Commencing Training ...\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/home/ko20929/.conda/envs/sktime_latest/lib/python3.11/site-packages/braindecode/models/base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n",
      "/user/home/ko20929/.conda/envs/sktime_latest/lib/python3.11/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "#1.Load the data ________________________________________________________________________________________\n",
    "\n",
    "\n",
    "for data_type in ['N3', 'REM', 'N2']:\n",
    "    for segment_length in [1024, 11520, 30720, 61440]:\n",
    "\n",
    "        df_list = joblib.load(data_type + '_normalised_dataframes.pkl')\n",
    "        \n",
    "        print(data_type)    \n",
    "        \n",
    "        # 1. generate all path names and class list(s) etc. \n",
    "        folder = '/user/home/ko20929/work/RBD_using_custom_package/Blue_pebble/'\n",
    "        paths = joblib.load(folder + data_type + '_paths.pkl') # keys : ['selected_paths', 's_class_list', 's_night_list', 's_sleep_type', 's_p_id']\n",
    "        \n",
    "        class_label_dict = {'HC': 0 , 'PD' : 1 , 'PD+RBD' : 2 , 'RBD' : 3} #Dictionary used to label the classes for reference\n",
    "        y = np.array([class_label_dict[c_name] for c_name in paths['s_class_list'] ] )\n",
    "        groups = paths['s_p_id']\n",
    "        \n",
    "        wake_dfs_binary = []\n",
    "        y_binary = []\n",
    "        groups_binary = []\n",
    "        \n",
    "        for df , class_label , group in zip(df_list, y, groups):\n",
    "            if class_label in [0,1]:\n",
    "                wake_dfs_binary.append(df)\n",
    "                y_binary.append(class_label)\n",
    "                groups_binary.append(group)\n",
    "        \n",
    "        y_binary = np.array(y_binary)\n",
    "    \n",
    "    #2. Generate 2 second segments of the data______________________________________________________________________ \n",
    "    \n",
    "        #segment_length is user input and overlap is user input at the start of the script\n",
    "        overlap = 0.5\n",
    "        \n",
    "        signal_slices = []\n",
    "        y_slice_labels = []\n",
    "        y_slice_groups = []\n",
    "        \n",
    "        for df, label, group in zip(wake_dfs_binary, y_binary, groups_binary):\n",
    "            \n",
    "            num_segments = int( np.floor(len(df)/segment_length) )\n",
    "            new_specs = []\n",
    "            \n",
    "            for i in np.arange(0,num_segments, 1 - overlap):\n",
    "                if i > num_segments - 1 :\n",
    "                    # I don't want it to try to take an incomplete slice\n",
    "                    # will be an incomplete slice causing errors downstream, needs to stop \n",
    "                    \n",
    "                    break\n",
    "                  \n",
    "                start_index = int( np.floor(i*segment_length) )\n",
    "                end_index = start_index + segment_length\n",
    "                \n",
    "                slice_df = df.iloc[start_index : end_index, :].copy()        \n",
    "                signal_slices.append(slice_df)\n",
    "                \n",
    "                y_slice_labels.append(label)\n",
    "                y_slice_groups.append(group)\n",
    "                \n",
    "        plt.hist(y_slice_labels)\n",
    "    \n",
    "    #3. Select the correct channels ______________________________________________________________________________\n",
    "        \n",
    "        channels_selected = eeg_14_channels # will later move this to the top of the notebook\n",
    "        \n",
    "        # signal_slices, y_slice_labels, y_slice_groups\n",
    "        signal_slices_14_channels = [ df.loc[:, channels_selected].copy() for df in signal_slices ]\n",
    "        \n",
    "        # Make the slices an np array of the correct dimensions\n",
    "        signal_slices_14_channels_np = [df.T.values for df in signal_slices_14_channels]\n",
    "    \n",
    "    #4. Create the network from the paper (REMOVED as I'm using EEG Conformer) \n",
    "    #The model is defined inside the training loop\n",
    "    \n",
    "    \n",
    "    #5. Do Train Validation Splits\n",
    "        # Train and Validation splits only ----> NO TEST\n",
    "        # spectrogram_slices, y_slice_labels and y_slice_groups to work with\n",
    "        train_val_dict = {}\n",
    "        \n",
    "        for value in ['train' , 'val']:\n",
    "            train_val_dict[value] = {}\n",
    "        \n",
    "        X = np.stack(signal_slices_14_channels_np)\n",
    "        y = np.array(y_slice_labels)\n",
    "        groups = np.array( [int(group) for group in y_slice_groups] )\n",
    "        \n",
    "        gkf = GroupKFold(n_splits = 4) \n",
    "        fold = 0\n",
    "        \n",
    "        for train_index, val_index   in gkf.split(X, y, groups*1):\n",
    "            fold += 1\n",
    "            \n",
    "            X_train, y_train, groups_train  = X[train_index], y[train_index] , groups[train_index]\n",
    "            X_val, y_val, groups_val =  X[val_index], y[val_index] , groups[val_index]   \n",
    "            \n",
    "            train_val_dict['train'][fold] = X_train, y_train, groups_train\n",
    "            train_val_dict['val'][fold]   = X_val, y_val, groups_val\n",
    "            \n",
    "            total_len = len(X) \n",
    "            val_percent = 100*(len(X_val) / total_len)\n",
    "            train_percent = 100*(len(X_train) / total_len)\n",
    "            \n",
    "            # Commented out the printing here\n",
    "            # print('fold ' + str(fold) ) \n",
    "            # print( str(train_percent)[:3] + ' | '  + str(val_percent)[:3] + ' |' )\n",
    "        \n",
    "            # # testing that the splits are as expected\n",
    "            # print( np.unique(groups_train) )\n",
    "            # print( np.unique(groups_val) )\n",
    "            \n",
    "            # print('__________________________________________________________________________')\n",
    "        \n",
    "        #Output from this section of code is X_train, y_train, groups_train AND X_test, y_test, groups_test \n",
    "        import time\n",
    "    \n",
    "        start_time = time.time()\n",
    "        \n",
    "        seeds = [2]\n",
    "        rows = len(seeds) # Make the figure the right size \n",
    "        \n",
    "        fig = plt.figure()\n",
    "        fig = plt.figure(figsize=(24,4*rows),dpi=100)\n",
    "        \n",
    "        # k is for subplots within the overall figure \n",
    "        \n",
    "        k = 1\n",
    "        print('Commencing Training ...')\n",
    "        # Test out for 1 fold to start with\n",
    "        \n",
    "        for fold in [1,2,3,4]:\n",
    "            print(fold)\n",
    "            X_train, y_train, groups_train = train_val_dict['train'][fold]\n",
    "            X_val, y_val, groups_val = train_val_dict['val'][fold]  \n",
    "            \n",
    "            # Creating train and test data loaders\n",
    "            train_data = [ (torch.from_numpy(input_slice).float().view(num_channels,segment_length), val) for input_slice, val in zip(X_train, y_train) ] \n",
    "            train_loader = DataLoader(train_data, batch_size=24, shuffle=True)\n",
    "            \n",
    "            val_data = [ (torch.from_numpy(input_slice).float().view(num_channels,segment_length), val) for input_slice, val in zip(X_val, y_val) ] \n",
    "            val_loader = DataLoader(val_data , batch_size=24, shuffle=False)\n",
    "            \n",
    "           \n",
    "            \n",
    "            \n",
    "            \n",
    "            # for seed in [2,5,15,50]:\n",
    "            for seed in seeds:\n",
    "                # set all seeds \n",
    "                random.seed(seed)\n",
    "                np.random.seed(seed)\n",
    "                torch.manual_seed(seed)\n",
    "                torch.cuda.manual_seed_all(seed) \n",
    "                \n",
    "                device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "                # print(device) - to check that device is actually cuda\n",
    "                \n",
    "                model = EEGConformer(\n",
    "                    n_chans = 14,\n",
    "                    n_outputs = 2 ,\n",
    "                    n_times=segment_length,\n",
    "                    final_fc_length = 'auto' \n",
    "                    )\n",
    "                \n",
    "                model.to(device)\n",
    "                \n",
    "                criterion = torch.nn.NLLLoss()\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr = 0.001 )\n",
    "    \n",
    "                \n",
    "                epochs = 35\n",
    "                train_losses = []\n",
    "                val_losses = []\n",
    "                test_losses = []\n",
    "                \n",
    "                train_correct = []\n",
    "                val_correct = []\n",
    "                test_correct = []\n",
    "                \n",
    "                for i in range(epochs):\n",
    "                    \n",
    "                    trn_corr = 0\n",
    "                    val_corr = 0\n",
    "                    tst_corr = 0\n",
    "                     \n",
    "                    \n",
    "                    trn_loss = 0\n",
    "                    val_loss = 0\n",
    "                    tst_loss = 0\n",
    "                    \n",
    "                    model.train()\n",
    "                    # Run the training batches\n",
    "                    for b, (X_train_batch, y_train_batch) in enumerate(train_loader):\n",
    "                        b+=1\n",
    "                \n",
    "                        #Move train data to the GPU\n",
    "                        X_train_batch = X_train_batch.to(device)\n",
    "                        y_train_batch = y_train_batch.to(device)\n",
    "                        \n",
    "                        # Apply the model\n",
    "                        y_pred = model(X_train_batch)  # we don't flatten X-train here\n",
    "                        loss = criterion(y_pred, y_train_batch)\n",
    "                 \n",
    "                        # Tally the number of correct predictions\n",
    "                        predicted = torch.argmax(torch.exp( y_pred.detach() ) ,  dim = 1 ) \n",
    "        \n",
    "                        predicted = predicted.reshape(y_train_batch.shape)\n",
    "                        \n",
    "                        batch_corr = (predicted == y_train_batch).sum()\n",
    "                        trn_corr += batch_corr\n",
    "                        trn_loss += loss\n",
    "                        \n",
    "                        # Update parameters\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                    train_losses.append(trn_loss)\n",
    "                    train_correct.append(trn_corr)\n",
    "                \n",
    "                    # Run the validation batches\n",
    "                    # Some of the variables in this loop have the same name as the variables in the above loop... be aware of that plz!\n",
    "                    model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        for b, (X_val_batch, y_val_batch) in enumerate(val_loader):\n",
    "                            b+=1\n",
    "                            \n",
    "                            #Move train data to the GPU\n",
    "                            X_val_batch = X_val_batch.to(device)\n",
    "                            y_val_batch = y_val_batch.to(device)\n",
    "                \n",
    "                            # Apply the model\n",
    "                            y_val = model(X_val_batch)\n",
    "                \n",
    "                            # Tally the number of correct predictions\n",
    "                            predicted = torch.argmax(y_val.detach(),  dim = 1 ) \n",
    "                            predicted = predicted.reshape(y_val_batch.shape)\n",
    "                            \n",
    "                            batch_corr = (predicted == y_val_batch).sum()\n",
    "                            val_corr += batch_corr\n",
    "                \n",
    "                            loss = criterion(y_val, y_val_batch)\n",
    "                            val_loss += loss \n",
    "                           \n",
    "                    val_losses.append(val_loss)\n",
    "                    val_correct.append(val_corr)\n",
    "                \n",
    "                    \n",
    "                   \n",
    "                \n",
    "                # Plot the outcome from the loop\n",
    "                \n",
    "                ax = fig.add_subplot(rows,4,k)\n",
    "                k+=1\n",
    "                plt.title('fold ' + str(fold), fontsize = 10)\n",
    "                plt.plot([(val.cpu() / len(X_train) ) for val in train_correct], label='training set accuracy')\n",
    "                plt.plot([(val.cpu()/len(X_val) ) for val in val_correct], label='validation set accuracy')\n",
    "                plt.ylabel('accuracy')\n",
    "                plt.xlabel('epochs') \n",
    "                plt.grid()\n",
    "            \n",
    "            \n",
    "            plt.tight_layout()\n",
    "        \n",
    "        \n",
    "        plt.legend()   \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        #Add text at the bottom of the figure\n",
    "        # fig.text(0.5, 0, 'This is a caption at the bottom of the figure | Model : ' + str(model) , va='bottom')\n",
    "        fig.text(0.5, 0, f'\\nDuration: {time.time() - start_time:.0f} seconds' , ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout(pad = 2.0)\n",
    "    \n",
    "        time_taken = str(segment_length/256)\n",
    "        channels_num = str(num_channels)\n",
    "        \n",
    "        save_name = 'Results/Folder_3/' + data_type + '_' + 'Conformer_window_' + time_taken + '_secs_' + channels_num + '_channels' \n",
    "        plt.savefig(save_name +'.png')\n",
    "            \n",
    "        \n",
    "        print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed  \n",
    "        print('Results Saved, on to next data type ...')\n",
    "        \n",
    "t2 = time.time()\n",
    "\n",
    "t2 - t1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
